{"meta":{"title":"飞光","subtitle":"","description":null,"author":"wzd","url":"http://example.com","root":"/"},"pages":[{"title":"分类","date":"2024-12-11T06:33:55.000Z","updated":"2025-01-29T06:14:53.730Z","comments":true,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2024-12-11T06:34:24.000Z","updated":"2025-01-29T06:14:53.924Z","comments":true,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"关于Collectors.groupingBy按照某个字段进行分组并排序的问题","slug":"关于Collectors-groupingBy按照某个字段进行分组并排序的问题","date":"2025-01-04T07:56:42.000Z","updated":"2025-01-29T06:14:53.730Z","comments":true,"path":"2025/01/04/关于Collectors-groupingBy按照某个字段进行分组并排序的问题/","permalink":"http://example.com/2025/01/04/%E5%85%B3%E4%BA%8ECollectors-groupingBy%E6%8C%89%E7%85%A7%E6%9F%90%E4%B8%AA%E5%AD%97%E6%AE%B5%E8%BF%9B%E8%A1%8C%E5%88%86%E7%BB%84%E5%B9%B6%E6%8E%92%E5%BA%8F%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"关于Collectors.groupingBy按照某个字段进行分组并排序的问题​ 最近，在工作中遇到一个问题，是关于Collectors.groupingBy 按照某个字段进行分组并排序的问题。特此记录。 ​ 众所周知，对一个 List&lt;Map&lt;String, Object&gt;&gt; 类型的集合，如果需要按照元素中的某个字段进行分组，通常使用 lambda 表达式对集合进行流处理。然后使用 Collectors.groupingBy 函数进行分组，此方法源码如下: 123public static &lt;T, K&gt; Collector&lt;T, ?, Map&lt;K, List&lt;T&gt;&gt;&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier) &#123; return groupingBy(classifier, toList());&#125; ​ 该方法需要一个 Function 函数。返回方法如下： 12345public static &lt;T, K, A, D&gt; Collector&lt;T, ?, Map&lt;K, D&gt;&gt; groupingBy(Function&lt;? super T, ? extends K&gt; classifier, Collector&lt;? super T, A, D&gt; downstream) &#123; return groupingBy(classifier, HashMap::new, downstream); &#125; ​ 从此方法中看出，除了一个 Function 函数外，还需要一个 默认的 HashMap，但是 HashMap 是一个无序集合，它存储键值对（key-value）但是不保证顺序。也就是说，当你遍历 HashMap 时，元素的顺序可能可插入的顺序无关。这是 HashMap 的特性，不像 LinkedHashMap 或者 TreeMap 那样可以保证顺序。所以，如果要保证按照某个字段进行分组后，还能同时保证排序，groupingBy 方法中需要将 HashMap 改为 LinkedHashMap 或者 TreeMap 即可。 示例如下：1、使用 HashMap 接收数据时：12345678910111213141516171819202122232425262728293031323334package com.example.demo.test;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Map;import java.util.stream.Collectors;public class Test &#123; public static void main(String[] args) &#123; List&lt;Map&lt;String, Object&gt;&gt; list = getDate(); Map&lt;Object, List&lt;Map&lt;String, Object&gt;&gt;&gt; dateMap = list.stream(). collect(Collectors.groupingBy(e -&gt; e.get(&quot;date&quot;))); System.out.println(dateMap); &#125; public static List&lt;Map&lt;String, Object&gt;&gt; getDate()&#123; List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;&gt;(); Map&lt;String, Object&gt; map1 = new HashMap&lt;&gt;(); Map&lt;String, Object&gt; map2 = new HashMap&lt;&gt;(); Map&lt;String, Object&gt; map3 = new HashMap&lt;&gt;(); map1.put(&quot;date&quot;, &quot;20240830&quot;); map1.put(&quot;value&quot;, &quot;张三1&quot;); map2.put(&quot;date&quot;, &quot;20240926&quot;); map2.put(&quot;value&quot;, &quot;张三2&quot;); map3.put(&quot;date&quot;, &quot;20241028&quot;); map3.put(&quot;value&quot;, &quot;张三3&quot;); list.add(map1); list.add(map2); list.add(map3); return list; &#125;&#125; ​ 执行 main 方法，返回的 dateMap 顺序应该和 list 中的添加顺序一致。打印结果如下： 1&#123;20240926=[&#123;date=20240926, value=张三2&#125;], 20241028=[&#123;date=20241028, value=张三3&#125;], 20240830=[&#123;date=20240830, value=张三1&#125;]&#125; ​ 结果并非如此。 2、使用 LinkedHashMap&#x2F;TreeMap 接收数据123456789101112131415161718192021222324252627282930313233343536373839404142package com.example.demo.test;import java.util.*;import java.util.stream.Collectors;/** * @Classname Test * @Description TODO * @Date 2025/1/4 14:59 * @Created by wangrui */public class Test &#123; public static void main(String[] args) &#123; List&lt;Map&lt;String, Object&gt;&gt; list = getDate(); Map&lt;Object, List&lt;Map&lt;String, Object&gt;&gt;&gt; linkedHashMap = list.stream() .collect(Collectors.groupingBy(e -&gt; e.get(&quot;date&quot;), LinkedHashMap::new, Collectors.toList())); Map&lt;Object, List&lt;Map&lt;String, Object&gt;&gt;&gt; treeMap = list.stream() .collect(Collectors.groupingBy(e -&gt; e.get(&quot;date&quot;), TreeMap::new, Collectors.toList())); System.out.println(&quot;linkedHashMap接收数据：&quot; + linkedHashMap); System.out.println(&quot;treeMap接收数据：&quot; + treeMap); &#125; public static List&lt;Map&lt;String, Object&gt;&gt; getDate()&#123; List&lt;Map&lt;String, Object&gt;&gt; list = new ArrayList&lt;&gt;(); Map&lt;String, Object&gt; map1 = new HashMap&lt;&gt;(); Map&lt;String, Object&gt; map2 = new HashMap&lt;&gt;(); Map&lt;String, Object&gt; map3 = new HashMap&lt;&gt;(); map1.put(&quot;date&quot;, &quot;20240830&quot;); map1.put(&quot;value&quot;, &quot;张三1&quot;); map2.put(&quot;date&quot;, &quot;20240926&quot;); map2.put(&quot;value&quot;, &quot;张三2&quot;); map3.put(&quot;date&quot;, &quot;20241028&quot;); map3.put(&quot;value&quot;, &quot;张三3&quot;); list.add(map3); list.add(map1); list.add(map2); return list; &#125;&#125; ​ 执行 main 方法，返回的 dateMap 顺序应该和 list 中的添加顺序一致。打印结果如下： 12linkedHashMap接收数据：&#123;20241028=[&#123;date=20241028, value=张三3&#125;], 20240830=[&#123;date=20240830, value=张三1&#125;], 20240926=[&#123;date=20240926, value=张三2&#125;]&#125;treeMap接收数据：&#123;20240830=[&#123;date=20240830, value=张三1&#125;], 20240926=[&#123;date=20240926, value=张三2&#125;], 20241028=[&#123;date=20241028, value=张三3&#125;]&#125; ​ 此时发现，linkedHashMap 接收数据是按照 list 插入元素的顺序进行排序的，但是 TreeMap 并非如此。这是因为 linkedHashMap 和 TreeMap 两者之间的差别。 1、LinkedHashMap: LinkedHashMap 保留了插入元素的顺序。这意味着， list 中的 date 元素（对应Map元素）出现的顺序会决定 LinkedHashMap 的顺序。 因此，linkedHashMap 中的键值对是按照 List 中的顺序排列的。 2、TreeMap： TreeMap 是一个基于红黑树的有序 Map 实现。它会对键进行自然排序（如果键实现了 Comparable 接口） 或者使用指定的 Comparator 进行排序。 由于 e.get(“date”) 此时的数据是一个String 类型，String 实现了 Comparable 接口，此时会按照自然顺序进行排序。这就是以上代码中， 使用 TreeMap 进行接收数据时，打印的结果是按照自然排序排列的原因。 因此，treeMap 中的键值对顺序可能与 list 的顺序不同，但一定是按键值的排序顺序排列的。","categories":[{"name":"Stream","slug":"Stream","permalink":"http://example.com/categories/Stream/"},{"name":"分组排序","slug":"Stream/分组排序","permalink":"http://example.com/categories/Stream/%E5%88%86%E7%BB%84%E6%8E%92%E5%BA%8F/"}],"tags":[{"name":"Stream","slug":"Stream","permalink":"http://example.com/tags/Stream/"},{"name":"分组排序","slug":"分组排序","permalink":"http://example.com/tags/%E5%88%86%E7%BB%84%E6%8E%92%E5%BA%8F/"}]},{"title":"SpringBoot的可扩展接口","slug":"SpringBoot的可扩展接口","date":"2024-12-22T03:58:26.000Z","updated":"2025-01-29T06:14:53.728Z","comments":true,"path":"2024/12/22/SpringBoot的可扩展接口/","permalink":"http://example.com/2024/12/22/SpringBoot%E7%9A%84%E5%8F%AF%E6%89%A9%E5%B1%95%E6%8E%A5%E5%8F%A3/","excerpt":"","text":"SpringBoot的可扩展接口本文转自 https://cloud.tencent.com/developer/article/2322443。 一、介绍​ 本文主要介绍 Spring 和 SpringBoot 在启动过程中涉及到的可扩展接口，以及各个扩展点的使用场景。并整理出一个 bean 在 Spring 内部从被加载到到最后初始化完成所有可扩展点的顺序调用图。 二、可扩展接口启动调用顺序图 三、ApplicationContextInitializer​ 该接口在 org.springframework.context 包下，这是整个 Spring 容器在刷新之前初始化 ConfigurableApplicationContext 的回调接口，简单来说就是在容器刷新之前调用此类的 initialize 方法。这个点允许用户自己扩展。用户可以在整个 Spring 容器还没有被初始化之前做一些事情。适用的场景：在开始激活一些配置，或者利用这个时候 class 还没有被类加载器加载的时机，进行动态字节码注入等操作。扩展方式如下： 1234567891011121314package com.example.demo;import org.springframework.context.ApplicationContextInitializer;import org.springframework.context.ConfigurableApplicationContext;public class ApplicationContextInitializerTest implements ApplicationContextInitializer&lt;ConfigurableApplicationContext&gt;&#123; @Override public void initialize(ConfigurableApplicationContext applicationContext) &#123; boolean active = applicationContext.isActive(); System.out.println(&quot;active=&quot; + active); System.out.println(&quot;ApplicationContextInitializerTest的initialize方法执行&quot;); &#125;&#125; ​ 因为此时容器还没有被初始化，想要扩展生效，有以下的几种方式： ​ 1、在启动类中将 ApplicationContextInitializerTest 对象添加到 SpringApplication 中。 123456789101112131415package com.example.demo;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@SpringBootApplicationpublic class DemoApplication &#123; public static void main(String[] args) &#123; SpringApplication springApplication = new SpringApplication(DemoApplication.class); springApplication.addInitializers(new ApplicationContextInitializerTest()); springApplication.run(args);// SpringApplication.run(DemoApplication.class, args); &#125;&#125; ​ 2、在配置文件中进行配置 1context.initializer.classes=com.example.demo.ApplicationContextInitializerTest ​ 3、利用Spring SPI扩展，在spring.factories中加入如下信息 1org.springframework.context.ApplicationContextInitializer=com.example.demo.ApplicationContextInitializerTest ​ 启动后打印如下信息: 1234567891011121314151617/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java ...... . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-17 17:21:13.605 INFO 45505 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.112024-12-17 17:21:13.605 DEBUG 45505 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.24...2024-12-17 17:21:13.973 INFO 45505 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.482 seconds (JVM running for 0.643) 四、BeanDefinitionRegistryPostProcessor​ 该接口在 org.springframework.beans.factory.support 包下，这个接口在读取项目中的 beanDefinition 之后执行，提供一个补充的扩展点。适用的场景：你可以在这里动态注册自己的 beanDefinition，可以加载 classpath之外的 bean。扩展方式如下： 1234567891011121314151617181920package com.example.demo;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;import org.springframework.beans.factory.support.BeanDefinitionRegistry;import org.springframework.beans.factory.support.BeanDefinitionRegistryPostProcessor;import org.springframework.stereotype.Component;@Componentpublic class BeanDefinitionRegistryPostProcessorTest implements BeanDefinitionRegistryPostProcessor &#123; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; System.out.println(&quot;BeanDefinitionRegistryPostProcessorTest的注册方法执行&quot;); &#125; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println(&quot;BeanDefinitionRegistryPostProcessorTest的postProcessBeanFactory方法执行&quot;); &#125;&#125; ​ 项目启动后打印日志如下： 123456789101112131415161718192021222324/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java ... . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-17 17:28:52.003 INFO 45585 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.112024-12-17 17:28:52.004 DEBUG 45585 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.24...BeanDefinitionRegistryPostProcessorTest的注册方法执行BeanDefinitionRegistryPostProcessorTest的postProcessBeanFactory方法执行...2024-12-17 17:28:52.385 INFO 45585 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.492 seconds (JVM running for 0.66) 五、BeanFactoryPostProcessor​ 该接口在 org.springframework.beans.factory.config 包下，这个接口是 beanFactory 的扩展接口，调用时机在 Spring 读取 bean Definition 信息之后，实例化 bean 之前。在这个时机，用户可以通过实现这个扩展接口来自行处理一些东西，比如修改已经注册的 beanDefinition 的元信息。扩展方式为： 1234567891011121314package com.example.demo;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.BeanFactoryPostProcessor;import org.springframework.beans.factory.config.ConfigurableListableBeanFactory;import org.springframework.stereotype.Component;@Componentpublic class BeanFactoryPostProcessorTest implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; System.out.println(&quot;BeanFactoryPostProcessorTest的postProcessBeanFactory方法执行&quot;); &#125;&#125; ​ 项目启动后打印日志如下： 1234567891011121314151617181920212223/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java.. . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-17 17:54:01.036 INFO 45814 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.112024-12-17 17:54:01.036 DEBUG 45814 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.242024-12-17 17:54:01.037 INFO 45814 --- [ main] com.example.demo.DemoApplication : No active profile set, falling back to 1 default profile: &quot;default&quot;BeanDefinitionRegistryPostProcessorTest的注册方法执行BeanDefinitionRegistryPostProcessorTest的postProcessBeanFactory方法执行BeanFactoryPostProcessorTest的postProcessBeanFactory方法执行..2024-12-17 17:54:01.408 INFO 45814 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.483 seconds (JVM running for 0.664) 六、InstantiationAwareBeanPostProcessor​ 该接口在 org.springframework.beans.factory.config 包下，接口继承了 BeanPostProcess 接口，区别如下： BeanPostProcess 接口只在 bean 的初始化阶段进行扩展（注入 Spring 上下文前后），而 InstantiationAwareBeanPostProcessor 接口在此基础上新增了三个方法（注意：本文的 Spring 版本为 v5.3.24），把可扩展的范围增加了实例化阶段和属性注入阶段。 postProcessBeforeInstantiation：实例化bean之前，相当于new这个bean之前。 postProcessAfterInstantiation：实例化bean之后，相当于new这个bean之后，属性填充之前被调用。 postProcessProperties：在属性填充阶段（即依赖注入）进行额外处理，例如：动态修改或计算属性值，条件性地注入属性值，为某些属性添加自定义逻辑。 **postProcessPropertyValues**（弃用）：bean已经实例化完成，在属性填充阶段触发，@Autowired,@Resource等注解原理基于此方法实现。 postProcessBeforeInitialization：初始化bean之前，相当于把bean注入spring上下文之前。 postProcessAfterInitialization：初始化bean之后，相当于把bean注入spring上下文之后。 ​ 适用场景：写中间件或者业务中，都能利用这个特性。比如对实现了某一类接口的 bean 在各个生命期间进行收集，或者对某个类型的 bean 进行统一的赋值等等。扩展方式如下： 12345678910111213141516171819202122232425262728293031323334353637383940package com.example.demo;import org.springframework.beans.BeansException;import org.springframework.beans.PropertyValues;import org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessor;import org.springframework.stereotype.Component;@Componentpublic class InstantiationAwareBeanPostProcessorTest implements InstantiationAwareBeanPostProcessor &#123; @Override public Object postProcessBeforeInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;InstantiationAwareBeanPostProcessorTest的postProcessBeforeInitialization方法被执行&quot;); return bean; &#125; @Override public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;InstantiationAwareBeanPostProcessorTest的postProcessAfterInitialization方法被执行&quot;); return bean; &#125; @Override public Object postProcessBeforeInstantiation(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; System.out.println(&quot;InstantiationAwareBeanPostProcessorTest的postProcessBeforeInstantiation方法被执行&quot;); return null; &#125; @Override public boolean postProcessAfterInstantiation(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;InstantiationAwareBeanPostProcessorTest的postProcessAfterInstantiation方法被执行&quot;); return true; &#125; @Override public PropertyValues postProcessProperties(PropertyValues pvs, Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;InstantiationAwareBeanPostProcessorTest的postProcessProperties方法被执行&quot;); return pvs; &#125;&#125; 七、SmartInstantiationAwareBeanPostProcessor​ 该接口在org.springframework.beans.factory.config 包下，此接口有三个触发方法： predictBeanType：该触发点发生在 postProcessBeforeInstantiation 之前(在图上并没有标明，因为一般不太需要扩展这个点)，这个方法用于预测 bean 的类型，返回第一个预测成功的 Class 类型，如果不能预测返回 null，当调用 BeanFactory.getType(name) 时通过 bean 的名字无法得到 bean 的类型信息时就调用该回调方法来决定类型信息。 determineCandidateConstructors：该触发点在 postProcessBeforeInstantiation 之后，用于确定该 bean 的构造函数，返回的是该 bean 的所有构造函数列表。用户可以扩展这个点，用来自定义选择相应的构造器来实例化这个 bean。 getEarlyBeanReference：该触发点发生在 postProcessBeforeInstantiation 之后，当有循环依赖场景时，当 bean 实例化好之后，为防止循环依赖，会提前暴露回调方法，用于 bean 实例化的后置处理。这个方法就是在提前暴露的回调方法中触发。 扩展方式如下： 1234567891011121314151617181920212223242526272829package com.example.demo;import org.springframework.beans.BeansException;import org.springframework.beans.factory.config.SmartInstantiationAwareBeanPostProcessor;import org.springframework.stereotype.Component;import java.lang.reflect.Constructor;@Componentpublic class SmartInstantiationAwareBeanPostProcessorTest implements SmartInstantiationAwareBeanPostProcessor &#123; @Override public Class&lt;?&gt; predictBeanType(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; System.out.println(&quot;predictBeanType方法执行&quot;); return beanClass; &#125; @Override public Constructor&lt;?&gt;[] determineCandidateConstructors(Class&lt;?&gt; beanClass, String beanName) throws BeansException &#123; System.out.println(&quot;determineCandidateConstructors方法执行&quot;); return null; &#125; @Override public Object getEarlyBeanReference(Object bean, String beanName) throws BeansException &#123; System.out.println(&quot;getEarlyBeanReference方法执行&quot;); return bean; &#125;&#125; 八、BeanFactoryAware​ 该接口位于 org.springframework.beans.factory 包下，这个接口只有一个触发点，发生在 bean 实例化之后，注入属性之前，也就是 set 之前。这个接口的扩展点方法为 setBeanFactory，可以拿到 BeanFactory 这个属性。 ​ 使用场景：可以在 bean 实例化之后，初始化之前，拿到 BeanFactory，在这个时候，可以对 bean 做特殊化的定制，也可以缓存 BeanFactory，后续拿来使用。扩展方式如下： 123456789101112131415package com.example.demo;import org.springframework.beans.BeansException;import org.springframework.beans.factory.BeanFactory;import org.springframework.beans.factory.BeanFactoryAware;import org.springframework.stereotype.Component;@Componentpublic class BeanFactoryAwareTest implements BeanFactoryAware &#123; @Override public void setBeanFactory(BeanFactory beanFactory) throws BeansException &#123; System.out.println(&quot;beanFactory=&quot; + beanFactory); &#125;&#125; 九、ApplicationContextAwareProcessor​ 该类位于 org.springframework.context.support 包下，这个类内部有七个扩展可供实现（本文的 Spring 版本为v5.3.24），这个类触发的时机发生在 bean 实例化之后，初始化之前。 1234567891011121314151617181920212223private void invokeAwareInterfaces(Object bean) &#123; if (bean instanceof EnvironmentAware) &#123; ((EnvironmentAware) bean).setEnvironment(this.applicationContext.getEnvironment()); &#125; if (bean instanceof EmbeddedValueResolverAware) &#123; ((EmbeddedValueResolverAware) bean).setEmbeddedValueResolver(this.embeddedValueResolver); &#125; if (bean instanceof ResourceLoaderAware) &#123; ((ResourceLoaderAware) bean).setResourceLoader(this.applicationContext); &#125; if (bean instanceof ApplicationEventPublisherAware) &#123; ((ApplicationEventPublisherAware) bean).setApplicationEventPublisher(this.applicationContext); &#125; if (bean instanceof MessageSourceAware) &#123; ((MessageSourceAware) bean).setMessageSource(this.applicationContext); &#125; if (bean instanceof ApplicationStartupAware) &#123; ((ApplicationStartupAware) bean).setApplicationStartup(this.applicationContext.getApplicationStartup()); &#125; if (bean instanceof ApplicationContextAware) &#123; ((ApplicationContextAware) bean).setApplicationContext(this.applicationContext); &#125; &#125; ​ 可以看到，该类用于执行各种驱动接口，在 bean 实例化之后，属性填充之后，通过执行上述 instanceof 后面标出的扩展接口，来获取对应容器的变量。 EnvironmentAware：用于获取 EnvironmentAware 的一个扩展类，可以获取系统内部的所有参数。 EmbeddedValueResolverAware：用于获取 StringValueResolver 的一个扩展类（EmbeddedValueResolverAware 接口中 setEmbeddedValueResolver 有一个 StringValueResolver 参数），StringValueResolver 用于获取基于 String 类型的 properties 的变量，一般我们用 @Value 注解的方式获取，如果实现了这个 Aware 接口，把 StringValueResolver 缓存起来，通过这个类去获取 String 类型的变量，效果是一样的。 ResourceLoaderAware：用于获取 ResourceLoader 的一个扩展类（同上），ResourceLoader 可以用于获取 classpath 内所有的资源对象，可以扩展此类来拿到 ResourceLoader 对象。 ApplicationEventPublisherAware：用于获取 ApplicationEventPublisher 的一个扩展类，ApplicationEventPublisher 可以用来发布事件，结合 ApplicationListener 来共同使用，下文在介绍 ApplicationListener 时会详细提到。这个对象也可以通过 spring 注入的方式来获得。 MessageSourceAware：用于获取 MessageSource 的一个扩展类， MessageSource 主要用来做国际化。 ApplicationStartupAware：用于获取 ApplicationStartup 的一个扩展类，主要提供一种方式用来追踪 Spring Boot 应用程序启动各个过程中的各个阶段，它允许你在应用程序启动时执行自定义的操作，比如记录启动的时间、日志、性能分析、监控等，帮助开发者分析启动性能。 ApplicationContextAware：用来获取 ApplicationContext 的一个扩展类，ApplicationContext 就是spring上下文管理器，可以手动的获取任何在 spring 上下文注册的 bean，我们经常扩展这个接口来缓存 spring 上下文，包装成静态方法。同时ApplicationContext 也实现了 BeanFactory，MessageSource，ApplicationEventPublisher 等接口，也可以用来做相关接口的事情。 十、BeanNameAware​ 这个接口位于 org.springframework.beans.factory 包下，该接口也是 Aware 扩展的一种，触发点在 bean 初始化之前，也就是 postProcessBeforeInitialization 之前，这个接口的触发方法只有一个：setBeanName。 ​ 使用场景：用户可以扩展这个点，在初始化 bean 之前拿到 Spring 容器中注册的 beanName，来自行修改这个 beanName 的值。 扩展方式如下： 123456789101112package com.example.demo;import org.springframework.beans.factory.BeanNameAware;import org.springframework.stereotype.Component;@Componentpublic class BeanNameAwareTest implements BeanNameAware &#123; @Override public void setBeanName(String name) &#123; System.out.println(&quot;name=&quot; + name); &#125;&#125; ​ 启动项目后，打印日志如下： 123456789101112131415161718192021/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java.. . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-18 14:17:47.217 INFO 49803 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.112024-12-18 14:17:47.218 DEBUG 49803 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.24..name=beanNameAwareTest2024-12-18 14:17:47.589 INFO 49803 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#x27;&#x27;2024-12-18 14:17:47.592 INFO 49803 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.493 seconds (JVM running for 0.657) 十一、@PostConstruct​ 这个注解，在包 javax.annotation 下，其作用是在 bean 的初始化阶段，如果一个方法标注了 @PostConstruct 注解，会先调用这个方法。这里重点是要关注这个标准的触发点，这个触发点是在 postProcessBeforeInitialization 之后，InitializingBean.afterPropertiesSet 之前。 ​ 使用场景：用户可以对某一方法进行标注，来进行初始化某一个属性。扩展方式如下： 12345678910111213141516171819package com.example.demo;import org.springframework.stereotype.Component;import javax.annotation.PostConstruct;@Componentpublic class Test &#123; public Test() &#123; System.out.println(&quot;test&quot;); &#125; @PostConstruct public void init()&#123; System.out.println(&quot;init&quot;); &#125;&#125; ​ 项目启动后打印日志如下： 1234567891011121314151617181920212223/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java.. . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-18 14:28:39.014 INFO 49906 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.112024-12-18 14:28:39.015 DEBUG 49906 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.24..testinit2024-12-18 14:28:39.381 INFO 49906 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#x27;&#x27;2024-12-18 14:28:39.385 INFO 49906 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.481 seconds (JVM running for 0.65) ​ init() 方法会在 Test 这个 bean 实例化并且依赖注入完成后执行，打印 init 日志。 十二、InitializingBean​ 该接口位于 org.springframework.beans.factory 包下，这个接口是用来初始化 bean 的。InitializingBean 为 bean 提供了初始化方法的方式：afterPropertiesSet 方法。凡是继承该接口的类，在初始化 bean 的时候都会执行该方法。这个扩展点触发的时机在 postProcessAfterInitialization 之前。 ​ 使用场景：用户实现此接口，来进行系统启动的时候一些业务指标的初始化工作。扩展方式如下： 12345678910111213package com.example.demo;import org.springframework.beans.factory.InitializingBean;import org.springframework.stereotype.Component;@Componentpublic class Test implements InitializingBean &#123; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println(&quot;afterPropertiesSet方法执行&quot;); &#125;&#125; 十三、FactoryBean​ 该接口位于 org.springframework.beans.factory 包下。一般情况下，Spring 通过反射机制利用 bean 的 class 属性指定支线类去实例化bean，在某些情况下，实例化 bean 过程比较复杂，如果按照传统的方式，则需要在 bean 中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。Spring为此提供了一个 FactoryBean 的工厂类接口，用户可以通过实现该接口定制实例化 Bean 的逻辑。FactoryBean 接口对于 Spring 框架来说占用重要的地位，Spring 自身就提供了70多个 FactoryBean 的实现。它们隐藏了实例化一些复杂 bean 的细节，给上层应用带来了便利。从Spring3.0开始，FactoryBean 开始支持泛型，即接口声明改为 FactoryBean 的形式 ​ 使用场景：用户可以扩展这个类，来为要实例化的 bean 做一个代理，比如为该对象的所有的方法作一个拦截，在调用前后输出一行log，模仿 ProxyFactoryBean 的功能。扩展方式为： 1234567891011121314151617181920212223242526272829package com.example.demo;import org.springframework.beans.factory.FactoryBean;import org.springframework.stereotype.Component;@Componentpublic class FactoryBeanTest implements FactoryBean&lt;FactoryBeanTest.A&gt; &#123; @Override public FactoryBeanTest.A getObject() throws Exception &#123; System.out.println(&quot;FactoryBeanTest.getObject&quot;); return new FactoryBeanTest.A(); &#125; @Override public Class&lt;?&gt; getObjectType() &#123; return FactoryBeanTest.A.class; &#125; @Override public boolean isSingleton() &#123; return true; &#125; public static class A&#123; &#125;&#125; 十四、SmartInitializingSingleton​ 该接口位于 org.springframework.beans.factory 包下。这个接口中只有一个方法 afterSingletonsInstantiated，其作用是 在spring 容器管理的所有单例对象（非懒加载对象）初始化完成之后调用的回调接口。其触发时机为 postProcessAfterInitialization 之后。 ​ 使用场景：用户可以扩展此接口在对所有单例对象初始化完毕后，做一些后置的业务处理。扩展方式为： 123456789101112package com.example.demo;import org.springframework.beans.factory.SmartInitializingSingleton;import org.springframework.stereotype.Component;@Componentpublic class SmartInitializingSingletonTest implements SmartInitializingSingleton &#123; @Override public void afterSingletonsInstantiated() &#123; System.out.println(&quot;afterSingletonsInstantiated方法执行&quot;); &#125;&#125; ​ 启动项目，打印日志如下： 123456789101112131415161718192021222324/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java... . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-22 11:34:21.014 INFO 66111 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.11 2024-12-22 11:34:21.015 DEBUG 66111 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.24...afterSingletonsInstantiated方法执行2024-12-22 11:34:21.368 INFO 66111 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#x27;&#x27;2024-12-22 11:34:21.371 INFO 66111 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.464 seconds (JVM running for 0.629) 十五、CommandLineRunner​ 位于 org.springframework.boot 包下，该接口只有一个方法 run(String… args) ，触发时机为整个项目启动完成后，自动执行，如果有多个 CommandLineRunner ，可以利用 @order 来进行排序。 ​ 使用场景：用户扩展此接口，进行启动项目之后一些业务的预处理。扩展方式如下： ​ 第一个实现类： 1234567891011121314package com.example.demo;import org.springframework.boot.CommandLineRunner;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;@Component@Order(1)public class CommandLineRunnerTest1 implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(&quot;CommandLineRunnerTest1执行&quot;); &#125;&#125; ​ 第二个实现类： 1234567891011121314package com.example.demo;import org.springframework.boot.CommandLineRunner;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;@Component@Order(2)public class CommandLineRunnerTest2 implements CommandLineRunner &#123; @Override public void run(String... args) throws Exception &#123; System.out.println(&quot;CommandLineRunnerTest2执行&quot;); &#125;&#125; 项目启动完成后，打印日志如下： 123456789101112131415161718192021222324/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java... . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-22 11:39:35.683 INFO 66170 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.112024-12-22 11:39:35.684 DEBUG 66170 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.24...2024-12-22 11:39:36.062 INFO 66170 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path &#x27;&#x27;2024-12-22 11:39:36.066 INFO 66170 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.494 seconds (JVM running for 0.659)CommandLineRunnerTest1执行CommandLineRunnerTest2执行 ​ 注意： @Order 注解中的值越小，优先级越高。 十六、DisposableBean​ 位于 org.springframework.beans.factory 包下，这个扩展点也只有一个方法：destroy()，其触发时机为当此对象销毁时，会自动执行这个方法。比如说运行 applicationContext.registerShutdownHook 时，就会触发这个方法。扩展方式如下： 123456789101112package com.example.demo;import org.springframework.beans.factory.DisposableBean;import org.springframework.stereotype.Component;@Componentpublic class TestDestory implements DisposableBean &#123; @Override public void destroy() throws Exception &#123; System.out.println(&quot;TestDestory 的 destroy 方法执行&quot;); &#125;&#125; ​ 新增一个接口如下： 12345678910111213141516package com.example.demo;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class HelloController &#123; @RequestMapping(value=&quot;/hello&quot;, method = RequestMethod.GET) public String hello1() throws Exception &#123; TestDestory testDestory = new TestDestory(); testDestory.destroy(); return &quot;hello&quot;; &#125;&#125; ​ 启动项目后，调用 http://localhost:8080/hello 接口，打印日志如下： 123456789101112131415161718192021222324/Library/Java/JavaVirtualMachines/jdk-17.jdk/Contents/Home/bin/java . ____ _ __ _ _ /\\\\ / ___&#x27;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\( ( )\\___ | &#x27;_ | &#x27;_| | &#x27;_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) &#x27; |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v2.7.7)active=falseApplicationContextInitializerTest的initialize方法执行2024-12-22 11:49:56.968 INFO 66316 --- [ main] com.example.demo.DemoApplication : Starting DemoApplication using Java 17.0.112024-12-22 11:49:56.969 DEBUG 66316 --- [ main] com.example.demo.DemoApplication : Running with Spring Boot v2.7.7, Spring v5.3.24...2024-12-22 11:49:57.347 INFO 66316 --- [ main] com.example.demo.DemoApplication : Started DemoApplication in 0.486 seconds (JVM running for 0.65)CommandLineRunnerTest2执行CommandLineRunnerTest1执行2024-12-22 11:50:03.198 INFO 66316 --- [nio-8080-exec-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring DispatcherServlet &#x27;dispatcherServlet&#x27;2024-12-22 11:50:03.198 INFO 66316 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Initializing Servlet &#x27;dispatcherServlet&#x27;2024-12-22 11:50:03.199 INFO 66316 --- [nio-8080-exec-1] o.s.web.servlet.DispatcherServlet : Completed initialization in 1 msTestDestory 的 destroy 方法执行","categories":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"}]},{"title":"Docker入门教程","slug":"Docker入门教程","date":"2024-12-11T11:50:54.000Z","updated":"2025-01-29T06:14:53.728Z","comments":true,"path":"2024/12/11/Docker入门教程/","permalink":"http://example.com/2024/12/11/Docker%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/","excerpt":"","text":"Docker入门教程一、Docker 用途Docker 的主要用途，目前有三大类。 （1）提供一次性的环境。比如，本地测试他人的软件、持续集成的时候提供单元测试和构建的环境。 （2）提供弹性的云服务。因为 Docker 容器可以随开随关，很适合动态扩容和缩容。 （3）组建微服务架构。通过多个容器，一台机器可以跑多个服务，因此在本机就可以模拟出微服务架构。 二、Docker 安装​ Docker 是一个开源的商业产品，有两个版本：社区版（Community Edition，缩写为 CE）和企业版（Enterprise Edition，缩写为 EE）。企业版包含了一些收费服务，个人开发者一般用不到。下面的介绍都针对社区版。 Windows安装 CentOs安装 ​ 安装完成后，运行下面的命令，验证是否安装成功。 123$ docker version# 或者$ docker info ​ Docker 需要用户具有 sudo 权限，为了避免每次命令都输入sudo，可以把用户加入 Docker 用户组（官方文档）。 1$ sudo usermod -aG docker $USER ​ Docker 是服务器—-客户端架构。命令行运行docker命令的时候，需要本机有 Docker 服务。如果这项服务没有启动，可以用下面的命令启动（官方文档）。 12345# service 命令的用法$ sudo service docker start# systemctl 命令的用法$ sudo systemctl start docker 三、image文件​ Docker 把应用程序以及所需的依赖打包在 image 文件里面。只有通过这个文件，才能生成 Docker 容器。image 文件可以看作是容器的模板。Docker 根据 image 文件生成容器的实例。同一个 image 文件，可以生成多个同时运行的容器实例。 ​ image 是二进制文件。实际开发中，一个 image 文件往往通过继承另一个 image 文件，加上一些个性化设置而生成。举例来说，你可以在 Ubuntu 的 image 基础上，往里面加入 Apache 服务器，形成你的 image。 12345# 列出本机的所有 image 文件。$ docker image ls# 删除 image 文件$ docker image rm [imageName] ​ image 文件是通用的，一台机器的 image 文件拷贝到另一台机器，照样可以使用。一般来说，为了节省时间，我们应该尽量使用别人制作好的 image 文件，而不是自己制作。即使要定制，也应该基于别人的 image 文件进行加工，而不是从零开始制作。 ​ 为了方便共享，image 文件制作完成后，可以上传到网上的仓库。Docker 的官方仓库 Docker Hub 是最重要、最常用的 image 仓库。此外，出售自己制作的 image 文件也是可以的。 四、实例：Hello World​ 下面，我们通过最简单的 image 文件”hello world”，感受一下 Docker。 ​ 需要说明的是，国内连接 Docker 的官方仓库很慢，还会断线，需要将默认仓库改成国内的镜像网站，具体的修改方法在下一篇文章的第一节。有需要的朋友，可以先看一下。 首先，运行下面的命令，将 image 文件从仓库抓取到本地。 1$ docker image pull library/hello-world ​ 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 由于 Docker 官方提供的 image 文件，都放在library组里面，所以它的是默认组，可以省略。因此，上面的命令可以写成下面这样。 1$ docker image pull hello-world ​ 抓取成功以后，就可以在本机看到这个 image 文件了。 1$ docker image ls ​ 现在，运行这个 image 文件。 1$ docker container run hello-world docker container run命令会从 image 文件，生成一个正在运行的容器实例。 ​ 注意，docker container run命令具有自动抓取 image 文件的功能。如果发现本地没有指定的 image 文件，就会从仓库自动抓取。因此，前面的docker image pull命令并不是必需的步骤。 如果运行成功，你会在屏幕上读到下面的输出。 123456$ docker container run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.... ... 输出这段提示以后，hello world就会停止运行，容器自动终止。 有些容器不会自动终止，因为提供的是服务。比如，安装运行 Ubuntu 的 image，就可以在命令行体验 Ubuntu 系统。 1$ docker container run -it ubuntu bash 对于那些不会自动终止的容器，必须使用docker container kill 命令手动终止。 1$ docker container kill [containID] 五、容器文件​ image 文件生成的容器实例，本身也是一个文件，称为容器文件。也就是说，一旦容器生成，就会同时存在两个文件： image 文件和容器文件。而且关闭容器并不会删除容器文件，只是容器停止运行而已。 12345# 列出本机正在运行的容器$ docker container ls# 列出本机所有容器，包括终止运行的容器$ docker container ls --all ​ 上面命令的输出结果之中，包括容器的 ID。很多地方都需要提供这个 ID，比如上一节终止容器运行的docker container kill命令。 终止运行的容器文件，依然会占据硬盘空间，可以使用docker container rm命令删除。 1$ docker container rm [containerID] 运行上面的命令之后，再使用docker container ls --all命令，就会发现被删除的容器文件已经消失了。 六、Dockerfile 文件​ 学会使用 image 文件以后，接下来的问题就是，如何可以生成 image 文件？如果你要推广自己的软件，势必要自己制作 image 文件。 这就需要用到 Dockerfile 文件。它是一个文本文件，用来配置 image。Docker 根据 该文件生成二进制的 image 文件。 下面通过一个实例，演示如何编写 Dockerfile 文件。 七、实例：制作自己的 Docker 容器​ 下面我以 koa-demos 项目为例，介绍怎么写 Dockerfile 文件，实现让用户在 Docker 容器里面运行 Koa 框架。 作为准备工作，请先下载源码。 12$ git clone https://github.com/ruanyf/koa-demos.git$ cd koa-demos ​ 首先，在项目的根目录下，新建一个文本文件.dockerignore，写入下面的内容。 123.gitnode_modulesnpm-debug.log ​ 上面代码表示，这三个路径要排除，不要打包进入 image 文件。如果你没有路径要排除，这个文件可以不新建。 然后，在项目的根目录下，新建一个文本文件 Dockerfile，写入下面的内容。 12345FROM node:8.4COPY . /appWORKDIR /appRUN npm install --registry=https://registry.npm.taobao.orgEXPOSE 3000 ​ 上面代码一共五行，含义如下。 12345FROM node:8.4：该 image 文件继承官方的 node image，冒号表示标签，这里标签是8.4，即8.4版本的 node。COPY . /app：将当前目录下的所有文件（除了.dockerignore排除的路径），都拷贝进入 image 文件的/app目录。WORKDIR /app：指定接下来的工作路径为/app。RUN npm install：在/app目录下，运行npm install命令安装依赖。注意，安装后所有的依赖，都将打包进入 image 文件。EXPOSE 3000：将容器 3000 端口暴露出来， 允许外部连接这个端口。 ​ 有了 Dockerfile 文件以后，就可以使用docker image build命令创建 image 文件了。 123$ docker image build -t koa-demo .# 或者$ docker image build -t koa-demo:0.0.1 . ​ 上面代码中，-t参数用来指定 image 文件的名字，后面还可以用冒号指定标签。如果不指定，默认的标签就是latest。最后的那个点表示 Dockerfile 文件所在的路径，上例是当前路径，所以是一个点。 如果运行成功，就可以看到新生成的 image 文件koa-demo了。 1$ docker image ls ​ 生成容器 docker container run命令会从 image 文件生成容器。 123$ docker container run -p 8000:3000 -it koa-demo /bin/bash# 或者$ docker container run -p 8000:3000 -it koa-demo:0.0.1 /bin/bash ​ 上面命令的各个参数含义如下： 1234-p参数：容器的 3000 端口映射到本机的 8000 端口。-it参数：容器的 Shell 映射到当前的 Shell，然后你在本机窗口输入的命令，就会传入容器。koa-demo:0.0.1：image 文件的名字（如果有标签，还需要提供标签，默认是 latest 标签）。/bin/bash：容器启动以后，内部第一个执行的命令。这里是启动 Bash，保证用户可以使用 Shell。 ​ 如果一切正常，运行上面的命令以后，就会返回一个命令行提示符。 1root@66d80f4aaf1e:/app# ​ 这表示你已经在容器里面了，返回的提示符就是容器内部的 Shell 提示符。执行下面的命令。 1root@66d80f4aaf1e:/app# node demos/01.js ​ 这时，Koa 框架已经运行起来了。打开本机的浏览器，访问","categories":[{"name":"docker","slug":"docker","permalink":"http://example.com/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"maven私服安装和使用","slug":"maven私服安装和使用","date":"2024-12-11T11:42:52.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/12/11/maven私服安装和使用/","permalink":"http://example.com/2024/12/11/maven%E7%A7%81%E6%9C%8D%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","excerpt":"","text":"maven私服安装和使用1、官网下载下载地址 本文主要是 Mac 安装，本文写于2024-05-07，下载的版本为 nexus-3.67.1-01-mac.tgz 注意：nexus3 的 环境必须为 jdk8 2、解压将文件复制到 &#x2F;Users&#x2F;xx&#x2F;environment&#x2F;nexus,存放的目录可以按照自己的喜好来。对文件进行解压。 1tar -zxvf nexus-3.67.1-01-mac.tgz 3、启动 nexus3.1、修改配置文件123456789101112131415cd /Users/xx/environment/nexus/nexus-3.67.1-01/etc # vim nexus-default.properties### Jetty sectionapplication-port=8081application-host=0.0.0.0nexus-args=$&#123;jetty.etc&#125;/jetty.xml,$&#123;jetty.etc&#125;/jetty-http.xml,$&#123;jetty.etc&#125;/jetty-requestlog.xmlnexus-context-path=/# Nexus sectionnexus-edition=nexus-pro-editionnexus-features=\\ nexus-pro-featurenexus.hazelcast.discovery.isEnabled=true 当前默认的的启动端口为8081，如果被占用，就换一个端口。nexus-context-path&#x3D;&#x2F; 为启动路径，后面可以按照自己的喜好进行拼接， 如果拼接了参数，nexus 启动成功后，打开的网页路径后面也需要拼接上拼接的参数。 3.2、启动进入 bin 目录，执行 启动命令 1./nexus run 注意：有些文档用的 nexus start 命令进行启动，本人试过，弹出 Starting nexus,但是实际上并没有启动。 3.3、访问地址访问 http://localhost:8081/ 进入首页，登陆账户为 admini, 以前 admin 的初始密码为 admin123，后来密码改为写在 sonatype-work&#x2F;nexus3&#x2F;admin.password 文件中。使用 vim 命令查看。登陆后记得修改密码。","categories":[{"name":"maven","slug":"maven","permalink":"http://example.com/categories/maven/"}],"tags":[{"name":"maven","slug":"maven","permalink":"http://example.com/tags/maven/"}]},{"title":"nginx入门","slug":"nginx入门","date":"2024-12-11T11:38:42.000Z","updated":"2025-01-29T06:14:53.730Z","comments":true,"path":"2024/12/11/nginx入门/","permalink":"http://example.com/2024/12/11/nginx%E5%85%A5%E9%97%A8/","excerpt":"","text":"Nginx一、简介​ 官方描述: 【nginx [engine x] is an HTTP and reverse proxy server, a mail proxy server, and a generic TCP&#x2F;UDP proxy server, According to Netcraft, nginx served or proxied 23.20% busiest sites in January 2021】nginx是一个Http服务器、反向代理服务器、邮件代理服务器、和通用TCP&#x2F;UDP代理服务器,根据Netcraft统计,截至2021年,它代理了世界上最繁忙的网站的比例达到了23.20%。 二、为什么使用nginx 根据Nginx中的官方网站的介绍我们知道,nginx的功能强大,在实际的工作中,我们会有很多场景会需要借助nginx来实现,比如: 1、想要访问外国的网站,但是因为某些原因,国内直接访问会被限制,因此可以通过nginx的正向代理来实现”科学上网”。 2、在某种工作环境下,项目部署在内网,无法访问外网的资源,可以使用nginx进行代理完成此需求。 3、项目是完全前后端分离开发,需要分布部署前后端项目,此时可以将前端项目部署到nginx中,因为nginx处理静态资源的效率比常见的应用服务器如Tomcat的要快很多。 4、nginx支持负载均衡,可以更大程度的提高服务器的使用效率。 5、除此之外,nginx还可以用作请求拦截,根据配置文件的配置,可以对请求路径进行自定义拦截。 三、nginx的功能 **1、缓存静态文件(html,css,js)**：实现完全的前后端分离,且它处理静态文件的效率是应用服务器的几倍。 2、反向代理: 当真实服务器不能被直接访问到时,nginx可作为反向代理服务,用于中间做转发 3、web缓存: 可以对不同的文件做不同的缓存处理，配置灵活，并且支持FastCGI_Cache，主要用于对FastCGI的动态程序进行缓存。配合着第三方的ngx_cache_purge，对制定的URL缓存内容可以的进行增删管理。 4、正向代理: 实现”科学上网” 5、负载均衡: 更大程度提高服务器的使用效率 6、邮件代理服务器: 实现轻松扩展邮件服务器的数量、根据不同的规则选择邮件服务器，例如，根据客户的IP地址选择最近的服务器,实现邮件服务器的负载均衡 四、nginx的常用命令​ 启动：.&#x2F;nginx 或者 .&#x2F;nginx -c &#x2F;配置文件的路径 停止: .&#x2F;nginx -s stop 重启: .&#x2F;nginx -s reload 检查配置文件: .&#x2F;nginx -t 查看nginx启动情况: ps -ef | grep nginx 注: 需要切换到安装好的nginx对应的sbin目录。 五:nginx的配置文件详解​ 注:nginx的配置文件在安装后的nginx目录下的conf文件夹中 (一):刚安装好的配置文件具体如下:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108#user nobody;worker_processes 1;#error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27; # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27; # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache&#x27;s document root # concurs with nginx&#x27;s one # #location ~ /\\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; (二)配置详解​ 1、根据上面的nginx配置文件,可以将nginx的配置分为以下的组成结构 123456789... #全局快events &#123; #events快&#125;http&#123; #http块 server &#123; #server快 location &#123; #location快 &#125; &#125;&#125; ​ 2、每块的结构功能 ​ (1)、全局块: 配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。 (2)、events块: 配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等 (3)、http块: 可以配置多个server,配置代理、缓存、日志定义等能和第三方模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 (4)、server块: 配置虚拟主机的相关参数，一个http中可以有多个server。 (5)、location块: 配置请求的路由，以及各种页面的处理情况。 ​ 3、nginx配置文件详细的解释 123456789101112131415161718192021222324252627282930313233343536373839########### 每个指令必须有分号结束。##################user administrator administrators; #配置用户或者组，默认为nobody nobody。#worker_processes 2; #允许生成的进程数，默认为1#pid /nginx/pid/nginx.pid; #指定nginx进程运行文件存放地址error_log log/error.log debug; #制定日志路径，级别。这个设置可以放入全局块，http块，server块，级别以此为：debug|info|notice|warn|error|crit|alert|emergevents &#123; accept_mutex on; #设置网路连接序列化，防止惊群现象发生，默认为on multi_accept on; #设置一个进程是否同时接受多个网络连接，默认为off #use epoll; #事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport worker_connections 1024; #最大连接数，默认为512&#125;http &#123; include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型，默认为text/plain #access_log off; #取消服务日志 log_format myFormat &#x27;$remote_addr–$remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $http_x_forwarded_for&#x27;; #自定义格式 access_log log/access.log myFormat; #combined为日志格式的默认值 sendfile on; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块。 sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限。 keepalive_timeout 65; #连接超时时间，默认为75s，可以在http，server，location块。 upstream mysvr &#123; server 127.0.0.1:7878; server 192.168.10.121:3333 backup; #热备 &#125; error_page 404 https://www.baidu.com; #错误页 server &#123; keepalive_requests 120; #单连接请求上限次数。 listen 4545; #监听端口 server_name 127.0.0.1; #监听地址 location ~*^.+$ &#123; #请求的url过滤，正则匹配，~为区分大小写，~*为不区分大小写。 #root path; #根目录 #index vv.txt; #设置默认页 proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 deny 127.0.0.1; #拒绝的ip allow 172.18.5.54; #允许的ip &#125; &#125;&#125; 六: nginx中常用的小知识1、配置文件中常用的变量,可以用于请求拦截或者匹配路由123456781.$remote_addr 与 $http_x_forwarded_for 用以记录客户端的ip地址；2.$remote_user ：用来记录客户端用户名称；3.$time_local ： 用来记录访问时间与时区；4.$request ： 用来记录请求的url与http协议；5.$status ： 用来记录请求状态；成功是200；6.$body_bytes_s ent ：记录发送给客户端文件主体内容大小；7.$http_referer ：用来记录从那个页面链接访问过来的；8.$http_user_agent ：记录客户端浏览器的相关信息； 2、location下常见的参数含义解释​ (1)、try_files参数(常用于部署前端项目时使用) ​ 具体含义:如: 请求路径是:http://localhost/demo，在location中配置:try_files $uri KaTeX parse error: Expected ‘EOF’, got ‘&amp;’ at position 30: …ml的含义: &amp;̲#8195;&amp;#…uri便是demo,try_files的作用,它会先去到硬盘中查找是否存在demo这个文件,如果存在则返回,如果不存在,则查找是否存在&#x2F;r o o t &#x2F; d e m o &#x2F; 的 目 目 录 ( root&#x2F;demo&#x2F; 的目目录(root&#x2F;demo&#x2F;的目目录(uri&#x2F;),如果找不到,则会fallback到try_files的最后一个选项index.html,发起一个内部 “子请求”，也就是相当于 nginx 发起一个 HTTP 请求到 http://localhost/index.html。 ​ (2)、root和index参数 ​ root：表示根目录、index：表示默认页 ​ (3)、proxy_set_header参数 ​ 用来重定义发往后端服务器的请求头，Value值可以是包含文本、变量或者它们的组合. ​ 格式: proxy_set_header Field Value; 原http请求的Header中的Host字段也放到转发的请求里。如果不加这一行的话，nginx转发的请求header里就不会有Host字段，而服务器是靠这个Host值来区分你请求的是哪个域名的资源的 ​ (4)、X-Forwarded-For参数 ​ 用途: 为了记录整个的代理过程，如果存在多层代理跳转的情况下,可以通过它来获取到被代理的客户端的地址。 ​ (5)、X-Real-IP参数 ​ 被代理的客户端的真是地址,在header里面的 X-Real-IP只是一个变量，后面的设置会覆盖前面的设置,一般只在第一个代理设置proxy_set_header X-Real-IP r e m o t e a d d r ; 就 好 了 ， 然 后 再 应 用 端 直 接 引 用 remote_addr;就好了，然后再应用端直接引用remoteaddr;就好了，然后再应用端直接引用http_x_real_ip就行.","categories":[{"name":"nginx","slug":"nginx","permalink":"http://example.com/categories/nginx/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://example.com/tags/nginx/"}]},{"title":"redis入门","slug":"redis入门","date":"2024-12-11T11:06:02.000Z","updated":"2025-01-29T06:14:53.730Z","comments":true,"path":"2024/12/11/redis入门/","permalink":"http://example.com/2024/12/11/redis%E5%85%A5%E9%97%A8/","excerpt":"","text":"Redis入门一、基础知识1Redis是单线程的！ 官方表示，Redis是基于内存操作，CPU不是Redis性能的瓶颈，Redis的瓶颈是机器的内存和网络带宽，所有使用单线程。 1为什么Redis单线程还这么快？ 1、误区1：高性能的服务器一定是多线程的？ 2、误区2：多线程一定比单线程效率高？ 核心：redis是将所有的数据全部放在内存中的，所有说使用单线程去操作效率就是最高的，对于内存系统来说，如果没有上下文切换，效率就是最高的。多次读写都是在一个CPU上的，在内存情况下，这个就是最佳方案。 二、Redis的五大数据类型2.1、Redis-key1234567127.0.0.1:6379&gt; EXPIRE name 10 #设置key过期时间，单位是秒(integer) 1127.0.0.1:6379&gt; ttl name #查看当前key的剩余时间(integer) 2127.0.0.1:6379&gt; type name #查看当前key的类型string 2.2、String（字符串）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136127.0.0.1:6379&gt; FLUSHALL #清空所有数据库OK127.0.0.1:6379&gt; set key1 v1 #设置值OK 127.0.0.1:6379&gt; get key1 #获取key1的值&quot;v1&quot;127.0.0.1:6379&gt; EXISTS key1 #判断key1的值是否存在(integer) 1 127.0.0.1:6379&gt; APPEND key1 &quot;hello&quot; #key1的值后面追加字符串，如果当前key不存在，则相当于set key(integer) 7127.0.0.1:6379&gt; get key1&quot;v1hello&quot;127.0.0.1:6379&gt; STRLEN key1 #获取字符串的长度(integer) 7127.0.0.1:6379&gt; APPEND key1 &quot;,wzd&quot;(integer) 11127.0.0.1:6379&gt; STRLEN key1(integer) 11127.0.0.1:6379&gt; get key1&quot;v1hello,wzd&quot;127.0.0.1:6379&gt; ##################################################################################127.0.0.1:6379&gt; set views 0 OK127.0.0.1:6379&gt; get views&quot;0&quot;127.0.0.1:6379&gt; INCR views #自增1(integer) 1127.0.0.1:6379&gt; get views&quot;1&quot;127.0.0.1:6379&gt; INCR views(integer) 2127.0.0.1:6379&gt; get views&quot;2&quot;127.0.0.1:6379&gt; DECR views #自减1(integer) 1127.0.0.1:6379&gt; DECR views(integer) 0127.0.0.1:6379&gt; DECR views(integer) -1127.0.0.1:6379&gt; INCRBY views 10 #自增10 可以设置步长指定增量(integer) 9127.0.0.1:6379&gt; INCRBY views 10(integer) 19127.0.0.1:6379&gt; DECRBY views 10(integer) 9###################################################################################字符串范围 range127.0.0.1:6379&gt; set key1 &quot;hello,wzd&quot; #设置key1的值OK127.0.0.1:6379&gt; get kye1 (nil)127.0.0.1:6379&gt; get key1&quot;hello,wzd&quot;127.0.0.1:6379&gt; GETRANGE key1 0 3 #截取字符串[0,3]&quot;hell&quot;127.0.0.1:6379&gt; GETRANGE key1 0 -1 #获取全部字符串，相当于get key&quot;hello,wzd&quot;#替换！127.0.0.1:6379&gt; set key2 abcdfgOK127.0.0.1:6379&gt; get kye2(nil)127.0.0.1:6379&gt; get key2&quot;abcdfg&quot;127.0.0.1:6379&gt; SETRANGE key2 1 xx #替换指定位置开始的字符串(integer) 6127.0.0.1:6379&gt; get key2&quot;axxdfg&quot;###################################################################################setex(set with expire) #设置过期时间#setnx(set if not exist) #不存在再设置(在分布式锁中常用)127.0.0.1:6379&gt; setex key3 30 &quot;hello&quot; #设置key3的值，30秒过期OK127.0.0.1:6379&gt; ttl key3(integer) 26127.0.0.1:6379&gt; get key3&quot;hello&quot; 127.0.0.1:6379&gt; SETNX mykey &quot;redis&quot; #如果mykey不存在，创建mykey(integer) 1127.0.0.1:6379&gt; keys *1) &quot;key1&quot;2) &quot;mykey&quot;3) &quot;key2&quot;127.0.0.1:6379&gt; ttl key3(integer) -2127.0.0.1:6379&gt; setnx mykey &quot;mongoDB&quot; #如果mykey存在，创建mykey失败(integer) 0127.0.0.1:6379&gt; get mykey&quot;redis&quot;##################################################################################msetmget127.0.0.1:6379&gt; MSET k1 v1 k2 v2 k3 v3 #同时设置多个值OK127.0.0.1:6379&gt; keys *1) &quot;k1&quot;2) &quot;k2&quot;3) &quot;k3&quot;127.0.0.1:6379&gt; mget k1 k2 k3 #同时获取多个值1) &quot;v1&quot;2) &quot;v2&quot;3) &quot;v3&quot;127.0.0.1:6379&gt; MSETNX k1 v1 k4 v4 #mset 是一个原子性的操作，要么一起成功，要么一起失败(integer) 0127.0.0.1:6379&gt; get k4(nil)#对象set user:1 &#123;name:zhangsan,age:3&#125; #设置一个user:1对象，值为json字符串来保存一个对象这里的key是一个巧妙的设计：user:&#123;id&#125;:&#123;filed&#125;,如此设置在redis中是ok的127.0.0.1:6379&gt; mset user:1:name zhangsan user:1:age 20OK127.0.0.1:6379&gt; mget user:1:name user:1:age1) &quot;zhangsan&quot;2) &quot;20&quot;##################################################################################getset #先get再set127.0.0.1:6379&gt; GETSET db redis #如果不存在值，则返回nil(nil)127.0.0.1:6379&gt; get db&quot;redis&quot;127.0.0.1:6379&gt; getset db mongodb #如果存在值，则返回原来的值，并设置新的值&quot;redis&quot;127.0.0.1:6379&gt; get db&quot;mongodb&quot;################################################################################## 2.3、List(列表)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697989910010110210310410510610710810911011111211311411511611711811912012112212312412512612712812913013113213313413513613713813914027.0.0.1:6379&gt; LPUSH list one #将一个值或者多个值插入列表的头部（左）(integer) 1127.0.0.1:6379&gt; LPUSH list two(integer) 2127.0.0.1:6379&gt; LPUSH list three(integer) 3127.0.0.1:6379&gt; LRANGE list 0 -1 #获取list中的值1) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;127.0.0.1:6379&gt; LRANGE list 0 1 #通过区间获取具体的值1) &quot;three&quot;2) &quot;two&quot;127.0.0.1:6379&gt; RPUSH list right #将一个值或者多个值插入列表的尾部（右）(integer) 4127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;right&quot;##################################################################################lpop #移除列表的的第一个元素rpop #移除列表的的最后一个元素127.0.0.1:6379&gt; LRANGE list 0 -1 1) &quot;three&quot;2) &quot;two&quot;3) &quot;one&quot;4) &quot;right&quot;127.0.0.1:6379&gt; LPOP list #移除列表的的第一个元素&quot;three&quot;127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;2) &quot;one&quot;3) &quot;right&quot;127.0.0.1:6379&gt; RPOP list #移除列表的的最后一个元素&quot;right&quot;127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;2) &quot;one&quot;##################################################################################Lindex127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;2) &quot;one&quot;127.0.0.1:6379&gt; LINDEX list 0 #通过下标获取list中的某一个值&quot;two&quot;##################################################################################Llen127.0.0.1:6379&gt; LPUSH list one(integer) 1127.0.0.1:6379&gt; LPUSH list two(integer) 2127.0.0.1:6379&gt; LPUSH list three(integer) 3127.0.0.1:6379&gt; LLEN list #返回列表的长度(integer) 3##################################################################################移除指定的值lrem 127.0.0.1:6379&gt; lrange list 0 -11) &quot;three&quot;2) &quot;three&quot;3) &quot;two&quot;4) &quot;one&quot;127.0.0.1:6379&gt; lrem list 1 one #移除list集合中指定个数的value,精确匹配(integer) 1127.0.0.1:6379&gt; lrange list 0 -1 1) &quot;three&quot;2) &quot;three&quot;3) &quot;two&quot;127.0.0.1:6379&gt; lrem list 1 three(integer) 1127.0.0.1:6379&gt; LPUSH list three(integer) 3127.0.0.1:6379&gt; lrem list 2 three(integer) 2127.0.0.1:6379&gt; LRANGE list 0 -11) &quot;two&quot;##################################################################################trim 截取127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello&quot;2) &quot;hello1&quot;3) &quot;hello2&quot;4) &quot;hello3&quot;127.0.0.1:6379&gt; LTRIM mylist 1 2 #通过下标截取指定的长度，这个list已经被改变，截断只剩下截取的元素OK127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello1&quot;2) &quot;hello2&quot;##################################################################################rpoplpush #移除列表的最后一个元素，并将此元素移动到一个新的列表中127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello2&quot;2) &quot;hello1&quot;3) &quot;hello&quot;127.0.0.1:6379&gt; RPOPLPUSH mylist myotherlist #移除列表的最后一个元素，并将此元素移动到一个新的列表中&quot;hello&quot;127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello2&quot;2) &quot;hello1&quot;127.0.0.1:6379&gt; LRANGE myotherlist 0 -11) &quot;hello&quot;##################################################################################lset #将列表中指定下标的值替换为另外一个值127.0.0.1:6379&gt; EXISTS list #判断这个列表是否存在(integer) 0127.0.0.1:6379&gt; lset list 0 item #不存在就会报错(error) ERR no such key127.0.0.1:6379&gt; LPUSH list value1 (integer) 1127.0.0.1:6379&gt; LRANGE list 0 01) &quot;value1&quot;127.0.0.1:6379&gt; lset list 0 item #如果存在，更新当前下标的值OK127.0.0.1:6379&gt; LRANGE list 0 0 1) &quot;item&quot;##################################################################################linsert #将具体的value插入到列表中某个元素的前面或者后面127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; LINSERT mylist before world other #将具体的value插入到列表中某个元素的前面(integer) 3127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello&quot;2) &quot;other&quot;3) &quot;world&quot;127.0.0.1:6379&gt; LINSERT mylist after world other #将具体的value插入到列表中某个元素的后面(integer) 4127.0.0.1:6379&gt; LRANGE mylist 0 -11) &quot;hello&quot;2) &quot;other&quot;3) &quot;world&quot;4) &quot;other&quot; 1小结 - 它实际上是一个列表，before Node after, left,right 都可以插入值 - 如果key不存在，创建新的链表 - 如果key存在，新增内容。 - 如果移除了所有的值，空链表，也代表不存在 - 在两边插入或者改动值，效率最高！中间元素，相对来说效率会低一点。 2.4、Set(集合)set中的值是不能重复的！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110127.0.0.1:6379&gt; sadd myset hello #set集合中添加元素(integer) 1127.0.0.1:6379&gt; sadd myset wzd(integer) 1127.0.0.1:6379&gt; sadd myset lov(integer) 1127.0.0.1:6379&gt; SMEMBERS myset #查看set的所有值1) &quot;wzd&quot;2) &quot;hello&quot;3) &quot;lov&quot;127.0.0.1:6379&gt; SISMEMBER myset hello #判断某一个值是不是在set集合中(integer) 1127.0.0.1:6379&gt; SISMEMBER myset word(integer) 0##################################################################################127.0.0.1:6379&gt; scard myset #获取set集合中的内容元素个数(integer) 3127.0.0.1:6379&gt; sadd myset wad(integer) 1127.0.0.1:6379&gt; sadd myset wzd #set集合无法添加重复的值(integer) 0127.0.0.1:6379&gt; scard myset(integer) 4##################################################################################127.0.0.1:6379&gt; SMEMBERS myset1) &quot;wzd&quot;2) &quot;hello&quot;3) &quot;wad&quot;4) &quot;lov&quot;127.0.0.1:6379&gt; srem myset wad #移除set集合中指定的元素(integer) 1127.0.0.1:6379&gt; SMEMBERS myset1) &quot;lov&quot;2) &quot;hello&quot;3) &quot;wzd&quot;##################################################################################set 无序不重复集合127.0.0.1:6379&gt; SRANDMEMBER myset #随机抽选出一个元素&quot;wzd&quot;127.0.0.1:6379&gt; SRANDMEMBER myset&quot;hello&quot;127.0.0.1:6379&gt; SRANDMEMBER myset&quot;wzd&quot;127.0.0.1:6379&gt; SRANDMEMBER myset 2 #随机抽选出指定个数的元素1) &quot;wzd&quot;2) &quot;lov&quot;127.0.0.1:6379&gt; SRANDMEMBER myset 21) &quot;hello&quot;2) &quot;lov&quot;##################################################################################删除指定的key，随机删除key127.0.0.1:6379&gt; SMEMBERS myset1) &quot;hello&quot;2) &quot;wzd&quot;3) &quot;lov&quot;127.0.0.1:6379&gt; spop myset #随机删除set中的元素&quot;lov&quot;127.0.0.1:6379&gt; spop myset&quot;hello&quot;127.0.0.1:6379&gt; SMEMBERS myset1) &quot;wzd&quot;##################################################################################SMOVE 将指定的值，移动到另外一个set集合中127.0.0.1:6379&gt; sadd myset hello(integer) 1127.0.0.1:6379&gt; sadd myset world(integer) 1127.0.0.1:6379&gt; sadd myset wzd(integer) 1127.0.0.1:6379&gt; sadd myset2 set2(integer) 1 127.0.0.1:6379&gt; SMOVE myset myset2 wzd #将myset中指定的值，移动到另外一个集合myset2中(integer) 1127.0.0.1:6379&gt; SMEMBERS myset21) &quot;set2&quot;2) &quot;wzd&quot;127.0.0.1:6379&gt; SMEMBERS myset1) &quot;world&quot;2) &quot;hello&quot;##################################################################################数字集合类 -差集 -交集 -并集127.0.0.1:6379&gt; SMEMBERS key 1) &quot;c&quot;2) &quot;b&quot;3) &quot;a&quot;127.0.0.1:6379&gt; SMEMBERS key11) &quot;c&quot;2) &quot;d&quot;3) &quot;e&quot;127.0.0.1:6379&gt; SDIFF key key1 #差集1) &quot;a&quot;2) &quot;b&quot;127.0.0.1:6379&gt; SINTER key key1 #交集1) &quot;c&quot;127.0.0.1:6379&gt; SUNION key key1 #并集1) &quot;c&quot;2) &quot;d&quot;3) &quot;a&quot;4) &quot;b&quot;5) &quot;e&quot; 2.5、Hash(哈希)Map集合，key-Map集合,本质和String类型没有太大区别 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061127.0.0.1:6379&gt; hset myhash field1 wzd #set一个具体 key-value(integer) 1127.0.0.1:6379&gt; hget myhash field1 #获取一个字段值&quot;wzd&quot;127.0.0.1:6379&gt; hmset myhash field1 hello field2 world #set多个 key-valueOK 127.0.0.1:6379&gt; hmget myhash field1 field2 #获取多个字段值1) &quot;hello&quot;2) &quot;world&quot;127.0.0.1:6379&gt; hgetall myhash #获取全部数据1) &quot;field1&quot;2) &quot;hello&quot;3) &quot;field2&quot;4) &quot;world&quot;127.0.0.1:6379&gt; hdel myhash field1 #删除hash指定的key字段，对应的value也就消失了(integer) 1127.0.0.1:6379&gt; hgetall myhash1) &quot;field2&quot;2) &quot;world&quot;##################################################################################hlen 127.0.0.1:6379&gt; hmset myhash field1 hello field2 worldOK127.0.0.1:6379&gt; HGETALL myhash1) &quot;field2&quot;2) &quot;world&quot;3) &quot;field1&quot;4) &quot;hello&quot;127.0.0.1:6379&gt; hlen myhash #获取hash表的字段数量(integer) 2##################################################################################127.0.0.1:6379&gt; HEXISTS myhash field1 #判断hash中指定的字段是否存在(integer) 1127.0.0.1:6379&gt; HEXISTS myhash field3(integer) 0##################################################################################只获得所有的field只获得所有的value127.0.0.1:6379&gt; hkeys myhash #获得所有的field1) &quot;field2&quot;2) &quot;field1&quot;127.0.0.1:6379&gt; HVALS myhash #获得所有的value1) &quot;world&quot;2) &quot;hello&quot;##################################################################################incr decr127.0.0.1:6379&gt; hset myhash field3 5 #指定增量(integer) 1127.0.0.1:6379&gt; HINCRBY myhash field3 1 (integer) 6127.0.0.1:6379&gt; HINCRBY myhash field3 -1(integer) 5127.0.0.1:6379&gt; hsetnx myhash field4 hello #如果不存在，则可以设置(integer) 1127.0.0.1:6379&gt; hsetnx myhash field4 world #如果存在，则不能设置(integer) 0 hash变更的的数据 user name age,尤其是用户信息之类的，经常变动的信息！hash更适合于对象的存储，String更加适合字符串存储 2.6、Zset(有序集合)在set的基础上，增加了一个值，set k1 v1 ,zse k1 score v1 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364127.0.0.1:6379&gt; ZADD myset 1 one #添加一个值(integer) 1127.0.0.1:6379&gt; ZADD myset 2 two 3 three #添加多个值(integer) 2127.0.0.1:6379&gt; ZRANGE myset 0 -1 #查看myset的所有值1) &quot;one&quot;2) &quot;two&quot;3) &quot;three&quot;##################################################################################排序如何实现127.0.0.1:6379&gt; ZADD salary 2500 xiaohong #添加三个用户的(integer) 1127.0.0.1:6379&gt; ZADD salary 5000 zhangsan(integer) 1127.0.0.1:6379&gt; ZADD salary 500 wzd(integer) 1127.0.0.1:6379&gt; ZRANGEBYSCORE salary -inf +inf #显示全部的用户，从小到大排序1) &quot;wzd&quot;2) &quot;xiaohong&quot;3) &quot;zhangsan&quot;127.0.0.1:6379&gt; ZREVRANGE salary 0 -1 #显示全部的用户，从大到小排序1) &quot;zhangsan&quot;2) &quot;wzd&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE salary -inf +inf withscores #显示全部用户，并且附带成绩1) &quot;wzd&quot;2) &quot;500&quot;3) &quot;xiaohong&quot;4) &quot;2500&quot;5) &quot;zhangsan&quot;6) &quot;5000&quot;127.0.0.1:6379&gt; ZRANGEBYSCORE salary -inf 2500 withscores #显示工资小于2500的员工的升序排列1) &quot;wzd&quot;2) &quot;500&quot;3) &quot;xiaohong&quot;4) &quot;2500&quot;##################################################################################移除元素127.0.0.1:6379&gt; ZRANGE salary 0 -11) &quot;wzd&quot;2) &quot;xiaoming&quot;3) &quot;zhangsan&quot;127.0.0.1:6379&gt; zrem salary xiaoming #移除元素(integer) 1127.0.0.1:6379&gt; ZRANGE salary 0 -11) &quot;wzd&quot;2) &quot;zhangsan&quot;127.0.0.1:6379&gt; zcard salary #获取有序集合中的个数(integer) 2##################################################################################127.0.0.1:6379&gt; zadd myset 1 hello (integer) 1127.0.0.1:6379&gt; zadd myset 2 world 3 wzd(integer) 2127.0.0.1:6379&gt; ZCOUNT myset 1 3 #获取指定区间的成员数量(integer) 3127.0.0.1:6379&gt; ZCOUNT myset 1 2(integer) 2 三、三种特殊数据类型3.1、geospatial 地理位置朋友的地位，附近的人，距离计算，使用redis的Geo,这个功能可以推算地理位置的信息，两地之间的距离，方圆几里的人！ 只有六个命令 123456GEOADDGEODISTGEOHASHGEOPOSGEORADIUSGEORADIUSBYMEMBER 1#geoadd 添加地理位置 1234567891011121314151617#规则：两极无法添加，我们一般会下载城市数据，直接通过java程序一次性导入#参数 key 值（经度、纬度、名称）#有效的经度从-180度到180度。#有效的纬度从-85.05112878度到85.05112878度。#当坐标位置超出上述指定范围时，该命令将会返回一个错误。127.0.0.1:6379&gt; geoadd china:city 39.90 116.40 beijing(error) ERR invalid longitude,latitude pair 39.900000,116.400000127.0.0.1:6379&gt; geoadd china:city 116.40 39.90 beijing #添加城市数据(integer) 1127.0.0.1:6379&gt; geoadd china:city 121.47 31.23 shanghai(integer) 1127.0.0.1:6379&gt; geoadd china:city 106.50 29.53 chongqin 114.05 22.52 shenzhen(integer) 2127.0.0.1:6379&gt; geoadd china:city 120.16 30.24 hangzhou 108.96 34.26 xian(integer) 2 1#geopos 从key里返回所有给定位置元素的位置（经度和纬度） 123456789127.0.0.1:6379&gt; geopos china:city beijing #获取指定的城市的经纬度1) 1) &quot;116.39999896287918091&quot; 2) &quot;39.90000009167092543&quot;127.0.0.1:6379&gt; geopos china:city beijing chongqin1) 1) &quot;116.39999896287918091&quot; 2) &quot;39.90000009167092543&quot;2) 1) &quot;106.49999767541885376&quot; 2) &quot;29.52999957900659211&quot; 12345678#geodist返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在， 那么命令返回空值。指定单位的参数 unit 必须是以下单位的其中一个m 表示单位为米。km 表示单位为千米。mi 表示单位为英里。ft 表示单位为英尺。 1234567127.0.0.1:6379&gt; GEODIST china:city beijing shanghai km #查看上海到北京的直线距离&quot;1067.3788&quot;127.0.0.1:6379&gt; GEODIST china:city beijing shanghai &quot;1067378.7564&quot;127.0.0.1:6379&gt; GEODIST china:city beijing chongqin km #查看重庆到北京的直线距离&quot;1464.0708&quot; 1234567#georadius 以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。范围可以使用以下其中一个单位：m 表示单位为米。km 表示单位为千米。mi 表示单位为英里。ft 表示单位为英尺。 我附近的人？（获取所有附近的人的地址，定位！）通过半径来查询！ 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; GEORADIUS china:city 110 30 1000 km #查询110，30这个经纬度为中心，寻找方圆1000km之内的所有城市1) &quot;chongqin&quot;2) &quot;xian&quot;3) &quot;shenzhen&quot;4) &quot;hangzhou&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km #查询当前位置500km之内的所有城市1) &quot;chongqin&quot;2) &quot;xian&quot; 127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withdist #查询当前位置500km之内的所有城市，包含直线距离1) 1) &quot;chongqin&quot; 2) &quot;341.9374&quot;2) 1) &quot;xian&quot; 2) &quot;483.8340&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withdist withcoord #查询当前位置500km之内的所有城市，包含直线距 离，经纬度1) 1) &quot;chongqin&quot; 2) &quot;341.9374&quot; 3) 1) &quot;106.49999767541885376&quot; 2) &quot;29.52999957900659211&quot;2) 1) &quot;xian&quot; 2) &quot;483.8340&quot; 3) 1) &quot;108.96000176668167114&quot; 2) &quot;34.25999964418929977&quot;127.0.0.1:6379&gt; GEORADIUS china:city 110 30 500 km withdist withcoord count 1 #查询当前位置500km之内的所有城市， 包含直线距离，经纬度，只查询一个1) 1) &quot;chongqin&quot; 2) &quot;341.9374&quot; 3) 1) &quot;106.49999767541885376&quot; 2) &quot;29.52999957900659211&quot; 12345678910#georadiusbymember 找出位于指定范围内的元素，GEORADIUSBYMEMBER 的中心点是由给定的位置元素决定的， 而不是像 GEORADIUS 那样， 使用输入的经度和纬度来决定中心点#找出位于指定元素周围的其他元素127.0.0.1:6379&gt; GEORADIUSBYMEMBER china:city beijing 1000 km 1) &quot;beijing&quot;2) &quot;xian&quot;127.0.0.1:6379&gt; GEORADIUSBYMEMBER china:city shanghai 400 km1) &quot;hangzhou&quot;2) &quot;shanghai&quot; 12#geohash返回一个或多个位置元素的 Geohash 表示 该命令将返回11个字符的Geohash字符串! 1234#将二维的经纬度转换为一维的字符串，如果两个字符串越接近，则距离越近127.0.0.1:6379&gt; GEOHASH china:city beijing chongqin1) &quot;wx4fbxxfke0&quot;2) &quot;wm5xzrybty0&quot; 123456789101112131415161718GEO底层的实现原理其实就是Zset!我们可以收用Zset命令来操作geo!127.0.0.1:6379&gt; ZRANGE china:city 0 -1 #查看地图中全部元素1) &quot;chongqin&quot; 2) &quot;xian&quot;3) &quot;shenzhen&quot;4) &quot;hangzhou&quot;5) &quot;shanghai&quot;6) &quot;beijing&quot;127.0.0.1:6379&gt; zrem china:city beijing #移除指定元素(integer) 1127.0.0.1:6379&gt; ZRANGE china:city 0 -11) &quot;chongqin&quot;2) &quot;xian&quot;3) &quot;shenzhen&quot;4) &quot;hangzhou&quot;5) &quot;shanghai&quot;127.0.0.1:6379&gt; 3.2、Hyperloglog 数据结构什么是基数？ A{1，3，5，7，8，7} B{1，3，5，7，8} 基数（不重复的元素）&#x3D; 5，可以接受误差。 简介 Redis Hyperloglog 基数统计的算法！ 优点：占用的内存是固定的，2^64不同元素的技术，只需要废12kb内存！ 123456789101112131415#测试使用127.0.0.1:6379&gt; PFADD mykey a b c d e f g h i j #创建第一组元素mykey(integer) 1127.0.0.1:6379&gt; PFCOUNT mykey #统计mykey中元素的基数数量(integer) 10127.0.0.1:6379&gt; PFADD mykey2 i j z x c v b n m #创建第一组元素mykey2(integer) 1127.0.0.1:6379&gt; PFCOUNT mykey2(integer) 9127.0.0.1:6379&gt; PFMERGE mykey3 mykey mykey2 #合并两组 mykey mykey2 =&gt; mykey3 并集OK127.0.0.1:6379&gt; PFCOUNT mykey3 #查看并集的数量(integer) 15 3.3、Bitmap 位图Bitmap 位图，数据结构，都是操作二进制来记录，就只有0和1两个状态！ 使用bitmap来记录 周一到周日的打卡！ 周一：1 周二：0 周三：0 周四：1 周五：1 周六：0 周日：0 12345678910111213141516#测试使用127.0.0.1:6379&gt; setbit sign 0 1(integer) 0127.0.0.1:6379&gt; setbit sign 1 0(integer) 0127.0.0.1:6379&gt; setbit sign 2 0(integer) 0127.0.0.1:6379&gt; setbit sign 3 1(integer) 0127.0.0.1:6379&gt; setbit sign 4 1(integer) 0127.0.0.1:6379&gt; setbit sign 5 0(integer) 0127.0.0.1:6379&gt; setbit sign 6 0(integer) 0 查看某一天是否打卡 1234127.0.0.1:6379&gt; GETBIT sign 3(integer) 1127.0.0.1:6379&gt; GETBIT sign 6(integer) 0 统计打卡的天数 12127.0.0.1:6379&gt; BITCOUNT sign #统计这周的打卡记录，就可以看到是否有全勤(integer) 3 四、事务Redis事务本质：一组命令的集合！一个事务中的所有命令都会被序列化，在事务执行过程中，会按照顺序执行！ 一次性、顺序性、排他性，执行一系列的命令！ 1--------- 队列 set set set 执行 ------------- Redis事务没有隔离级别的概念 所有的命令在事务中，并没有被执行，只有发起执行命令的时候才会执行（Exec）！ Redis单条命令是保证原子性的，但是redis事务不保证原子性！ redis的事务： - 开启事务（Multi） - 命令入队（...） - 执行事务（exec） 123456789101112131415161718#正常执行事务！127.0.0.1:6379&gt; MULTI #开启事务OK#入队命令127.0.0.1:6379&gt; set k1 v1QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; get k2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; EXEC #执行事务1) OK2) OK3) &quot;v2&quot;4) OK 1#放弃事务 1234567891011121314127.0.0.1:6379&gt; MULTI #开启事务OK#入队命令127.0.0.1:6379&gt; set k1 v1 QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k4 v4QUEUED127.0.0.1:6379&gt; DISCARD #取消事务OK127.0.0.1:6379&gt; get k4 #事务队列中的命令都不会执行(nil) 1编译型异常（命令有错！），事务中所有的命令都不会被执行 1234567891011121314151617181920127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; set k1 v1 QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; getset k3 #错误的命令(error) ERR wrong number of arguments for &#x27;getset&#x27; command127.0.0.1:6379&gt; set k4 v4QUEUED127.0.0.1:6379&gt; set k5 v5QUEUED127.0.0.1:6379&gt; EXEC #执行事务报错(error) EXECABORT Transaction discarded because of previous errors.127.0.0.1:6379&gt; get k5 #所有的命令都不会被执行(nil)127.0.0.1:6379&gt; get k2 #所有的命令都不会被执行(nil) 1运行时异常,如果事务队列中存在语法错误，那么执行命令的时候，其他命令是可以正常执行的，错误命令会抛出异常！ 123456789101112131415161718192021127.0.0.1:6379&gt; set k1 &quot;v1&quot;OK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; INCR k1 #执行的时候失败QUEUED127.0.0.1:6379&gt; set k2 v2QUEUED127.0.0.1:6379&gt; set k3 v3QUEUED127.0.0.1:6379&gt; get k3 QUEUED127.0.0.1:6379&gt; EXEC1) (error) ERR value is not an integer or out of range #虽然第一条命令报错了，但是依旧正常执行成功了2) OK3) OK4) &quot;v3&quot;127.0.0.1:6379&gt; get k2&quot;v2&quot;127.0.0.1:6379&gt; get k3&quot;v3&quot; 1监控！ Watch 4.1、悲观锁： 很悲观，认为什么时候都会出问题，无论做什么都会加锁！ 4.2、乐观锁： 很乐观，认为什么时候都不会出问题，所有不会上锁！更新数据的时候去判断一下，在此期间是否有人修改过数据。 获取version 更新的时候比较version 1Redis的监视测试 正常执行成功！ 12345678910111213141516127.0.0.1:6379&gt; set money 100OK127.0.0.1:6379&gt; WATCH money #监视 money 对象OK127.0.0.1:6379&gt; set out 0 OK127.0.0.1:6379&gt; MULTI #事务正常结束，数据期间没有发生变动，这个时候就正常执行成功OK127.0.0.1:6379&gt; DECRBY money 20QUEUED127.0.0.1:6379&gt; INCRBY out 20QUEUED127.0.0.1:6379&gt; EXEC1) (integer) 802) (integer) 20 测试多线程修改值，使用watch可以当作redis的乐观锁操作！ 12345678910111213141516127.0.0.1:6379&gt; get money &quot;80&quot;127.0.0.1:6379&gt; watch money #监视moneyOK127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; DECRBY money 10QUEUED127.0.0.1:6379&gt; INCRBY out 10QUEUED127.0.0.1:6379&gt; EXEC #执行之前，另外一个线程修改了money的值，这个时候就会导致事务执行失败(nil)127.0.0.1:6379&gt; unwatch #取消监视money(如果事务执行失败，先解锁)OK127.0.0.1:6379&gt; watch money #重新监视money（获取锁）OK 五、Redis持久化5.1、RDB （Redis DataBase)1234触发机制1、save规则满足的情况下，，会触发rdb规则2、执行flushall命令，也会出发rdb规则3、退出redis，也会产生rdb文件 备份就会自动生成一个dump.rdb文件。 如何恢复rdb文件？ 1只需要将rdb文件放到redis启动目录下就可以，redis启动时会自动检查dump.rdb文件，恢复其中的数据 123127.0.0.1:6379&gt; config get dir1) &quot;dir&quot;2) &quot;/usr/local/bin&quot; #如果在这个目录下存在dump.rdb文件，启动redis就会自动恢复其中的数据 优点： 1、适合大规模的数据恢复! 2、对数据的完整性要求不高！ 缺点： 1、需要一定的时间间隔进行操作，如果redis意外宕机了，最后一次修改的数据就没有了！ 2、fock进程的时候，会占用一定的内存空间！ 5.2、AOF (Append Only File)将我们所有的命令记录下来，恢复的时候把这个文件全部再执行一遍。 以日志的形式来记录每个写操作，将Redis执行过的所有指令记录下来（读操作不记录），只追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据。 Aof保存的是appendinly.aof文件 默认是不开启的，需要手动进行配置！我们只需要将appendonly 改为yes就开启了aof. 重启redis就可以生效。 如果这个aof文件有错误，这时候redis是启动不起来的，我们需要修复aof文件，redis给我们提供了这样一个工具 redis-check-aof –fix 123456[root@localhost bin]# redis-check-aof --fix appendonly.aof 0x 4d: Expected \\r\\n, got: 6176AOF analyzed: size=84, ok_up_to=52, diff=32This will shrink the AOF from 84 bytes, with 32 bytes, to 52 bytesContinue? [y/N]: ySuccessfully truncated AOF 如果文件正常，重启就可以恢复了。 优点： 1、每次修改都同步，文件完整性更加好 2、每秒同步一次，可能会丢失一秒的数据 缺点： 1、相对于数据文件来说，aof远远大于rdb,修复的速度也比rdb慢。 2、aof运行效率也要比rdb慢，所有redis默认的配置就是rdb持久化！ 六、Redis主从复制6.1、环境配置只配置从库，不用配置主库！ 12345678910111213127.0.0.1:6379&gt; info replication #查看当前库的信息# Replicationrole:master #角色，masterconnected_slaves:0 #没有从机master_replid:f71f9f3e820529cb1d83e8481168f13d59a35b0dmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:0repl_backlog_size:1048576repl_backlog_first_byte_offset:0repl_backlog_histlen:0 赋值三个配置文件，修改对应的信息 1、端口 2、pid名字 3、log文件 4、dump.rdb名字 修改完毕后启动三个redis服务器，可以通过进程查看信息。 6.2、一主二从默认情况下，每台redis服务器都是主节点，我们一般情况值用配置从机就好了。 一主（79）二从（80、81） 1234567891011121314151617181920212223242526272829303132333435363738127.0.0.1:6380&gt; SLAVEOF 127.0.0.1 6379 # SLAVEOF host 6379 找谁当自己的老大OK127.0.0.1:6380&gt; info replication# Replicationrole:slave #当前角色 从机master_host:127.0.0.1 #可以看到主机的地址信息master_port:6379 #可以看到主机的端口信息master_link_status:upmaster_last_io_seconds_ago:3master_sync_in_progress:0slave_repl_offset:0slave_priority:100slave_read_only:1connected_slaves:0master_replid:5d10c8af41a828c211df6393826247d9f2894398master_replid2:0000000000000000000000000000000000000000master_repl_offset:0second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:0#在主机中查看信息127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:1 #多了从机的配置slave0:ip=127.0.0.1,port=6380,state=online,offset=126,lag=1 #从机信息master_replid:5d10c8af41a828c211df6393826247d9f2894398master_replid2:0000000000000000000000000000000000000000master_repl_offset:126second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:126 12345678910111213141516#如果两个都配置完了，就是有两个从机了127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2 #从机个数slave0:ip=127.0.0.1,port=6380,state=online,offset=406,lag=0 #从机1信息slave1:ip=127.0.0.1,port=6381,state=online,offset=406,lag=0 #从机2信息master_replid:5d10c8af41a828c211df6393826247d9f2894398master_replid2:0000000000000000000000000000000000000000master_repl_offset:406second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:406 真实的主从配置应该在配置文件中配置，这样的话是永久的，我们这里使用命令来配置，是暂时的。 1234细节： 主机可以写，从机只能读不能写！主机中所有的信息和数据，都会自动被从机保存。 当主机断开连接，从机依旧连接到主机的，但是没有写操作，这个时候，主机如果回来了，从机依旧可以获取主机写入的信息。 如果是使用命令行，来配置的主从，从机这个时候如果重启了，就会变回主机，只有再次变为79的从机，立马就能从主机中获取所有数据。 6.3、哨兵模式（自动选举老大的模式） 1测试 1我们目前的状态是一主二从 1、配置哨兵配置文件sentinel.conf 12#sentinel monitor 被监控的名称 host port &lt;quorum&gt; ，&lt;quorum&gt;:配置了多少个sentinel哨兵统一认为master主节点失联，那么这时客观上认为主节点失联了。sentinel monitor myredis 127.0.0.1 6379 1 2、启动哨兵 1234567891011121314151617181920212223242526272829[root@localhost bin]# redis-sentinel wconfig/sentinel.conf 3608:X 06 Nov 2020 16:22:58.841 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo3608:X 06 Nov 2020 16:22:58.841 # Redis version=6.0.6, bits=64, commit=00000000, modified=0, pid=3608, just started3608:X 06 Nov 2020 16:22:58.841 # Configuration loaded3608:X 06 Nov 2020 16:22:58.842 * Increased maximum number of open files to 10032 (it was originally set to 1024). _._ _.-``__ &#x27;&#x27;-._ _.-`` `. `_. &#x27;&#x27;-._ Redis 6.0.6 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &#x27;&#x27;-._ ( &#x27; , .-` | `, ) Running in sentinel mode |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;| Port: 26379 | `-._ `._ / _.-&#x27; | PID: 3608 `-._ `-._ `-./ _.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | http://redis.io `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; `-._ `-.__.-&#x27; _.-&#x27; `-._ _.-&#x27; `-.__.-&#x27; 3608:X 06 Nov 2020 16:22:58.843 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.3608:X 06 Nov 2020 16:22:58.845 # Sentinel ID is 00586711845405f9b432187d56bf6fcd567262e03608:X 06 Nov 2020 16:22:58.845 # +monitor master myredis 127.0.0.1 6379 quorum 13608:X 06 Nov 2020 16:22:58.846 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:22:58.848 * +slave slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 6379 如果master节点断开了，这个时候就会从从机中随机选择一个服务器！（这里面有一个投票算法） 12345678910111213143608:X 06 Nov 2020 16:25:10.705 # +selected-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:10.705 * +failover-state-send-slaveof-noone slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:10.775 * +failover-state-wait-promotion slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:11.351 # +promoted-slave slave 127.0.0.1:6381 127.0.0.1 6381 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:11.351 # +failover-state-reconf-slaves master myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:11.417 * +slave-reconf-sent slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:12.368 * +slave-reconf-inprog slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:12.368 * +slave-reconf-done slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:12.471 # +failover-end master myredis 127.0.0.1 63793608:X 06 Nov 2020 16:25:12.471 # +switch-master myredis 127.0.0.1 6379 127.0.0.1 63813608:X 06 Nov 2020 16:25:12.471 * +slave slave 127.0.0.1:6380 127.0.0.1 6380 @ myredis 127.0.0.1 63813608:X 06 Nov 2020 16:25:12.471 * +slave slave 127.0.0.1:6379 127.0.0.1 6379 @ myredis 127.0.0.1 63813608:X 06 Nov 2020 16:25:42.482 # +sdown slave 127.0.0.1:6379 127.0.0.1 6379 @ myredis 127.0.0.1 6381 12345678910111213127.0.0.1:6381&gt; info replication# Replicationrole:masterconnected_slaves:1slave0:ip=127.0.0.1,port=6380,state=online,offset=12533,lag=1master_replid:8dd070fc6ce1485eaabcf12c2515144c4b4c576cmaster_replid2:c1e23431f8b5ebafe4eab3671e92c05fd4ec564cmaster_repl_offset:12533second_repl_offset:8467repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:43repl_backlog_histlen:12491 如果此时主机回来了，只能归并到新的主机下，成为从机。这就是哨兵模式的规则。 哨兵模式： 优点： 1、哨兵集群，基于主从复制模式，所有主从赋值优点，它全有。 2、主从可以切换，故障可以转义，系统可用性更好。 3、哨兵模式就是主从模式的升级，手动到自动。 缺点： 1、redis不好在线扩容，集群容量一旦到达上限，在线扩容就十分麻烦。 2、实现哨兵模式的配置很麻烦，里面有很多选择。 七、Redis缓存穿透和雪崩暂定","categories":[{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}]},{"title":"docker 安装 nacos v1.4.7","slug":"docker-安装-nacos-v1-4-7","date":"2024-08-06T01:04:07.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/08/06/docker-安装-nacos-v1-4-7/","permalink":"http://example.com/2024/08/06/docker-%E5%AE%89%E8%A3%85-nacos-v1-4-7/","excerpt":"docker 安装 nacos v1.4.71、下载镜像1docker pull nacos/nacos-server:v1.4.7","text":"docker 安装 nacos v1.4.71、下载镜像1docker pull nacos/nacos-server:v1.4.7 2、创建容器网络1docker network create nacos_network 3、启动容器12345docker run --name nacos -d \\-p 8848:8848 \\--network nacos_network \\-e MODE=standalone \\nacos/nacos-server ​ 这个命令会启动一个名为 nacos 的容器，并将其绑定到物理机的 8848 端口。同时，它还会将容器添加到之前创建的 nacos_network 容器网络中，并设置容器模式为 standalone（单机）。 123456docker run --name nacos2.2.0 -d \\-p 8848:8848 \\-p 9848:9848 \\--network nacos_network \\-e MODE=standalone \\nacos/nacos-server:v2.2.0 环境：Nacos版本 2.2.0，docker镜像，centos8问题描述：页面访问正常，curl -X POST正常，但是使用Java SDK集成发布失败原因定位：跟踪源码，异常描述： Client not connected,current status:STARTING，客户端gRPC无法和服务端创建链接，在Nacos2.X版本中，增加了gRPC通信端口，需要由docker一并映射出来，否则就会出现无法初始化连接。解决方案：在docker容器中映射9848端口 4、访问 Nacos Web 控制台启动完 Nacos 容器后，就可以通过 http:&#x2F;&#x2F;虚拟机IP:8848&#x2F;nacos 访问 Nacos Web 控制台了。在控制台上，可以进行服务注册、配置管理和服务发现等操作 5、配置 Nacos 数据库存储​ 默认情况下，Nacos 使用内置的 Derby 数据库进行数据存储。虽然 Derby 是一个轻量级的数据库，但当数据量较大时，它可能会导致性能瓶颈和数据丢失的问题。因此，建议将 Nacos 数据库存储改为 MySQL 或 PostgreSQL 等外部数据库。 步骤 1：安装 MySQL 数据库​ 首先，需要在本地机器或其他服务器上安装 MySQL 数据库，请参照https://gitee.com/wangzhidao/document-warehouse/tree/master/%E6%96%87%E6%A1%A3/docker。 步骤 2：创建 Nacos 数据库和用户​ 安装完成 MySQL 后，启动mysql，容器需要创建一个新的数据库和用户，并授予其访问权限。可以使用以下命令创建一个名为 nacos 的数据库和用户： 1docker exec -it [容器ID] /bin/bash 1234567mysql -u root -pCREATE DATABASE nacos DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;CREATE USER &#x27;nacos&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27;;GRANT ALL PRIVILEGES ON nacos.* TO &#x27;nacos&#x27;@&#x27;%&#x27;;FLUSH PRIVILEGES;EXIT;EXIT; ​ 这样，就创建了一个名为 nacos 的数据库和一个名为 nacos 的用户，并赋予它们访问权限。 步骤 3：修改 Nacos 配置文件​ 在启动 Nacos 容器之前，需要修改配置文件以将 Nacos 数据库存储改为 MySQL。 首先，需要找到容器内部的 nacos 目录，可以使用以下命令进入容器内部： 12docker exec -it nacos /bin/bashcd /home/nacos/conf 在 conf 目录下，可以找到 application.properties 文件。将该文件拷贝到本地机器上，并使用文本编辑器打开该文件。 ​ 1 、从容器拷贝文件到宿主机 ​ docker cp 容器名：容器中要拷贝的文件名及其路径 要拷贝到宿主机里面对应的路径 1docker cp nacos:/home/nacos/conf/application.properties /home/wzd/ ​ 2、从宿主机拷贝文件到容器 ​ docker cp 宿主机中要拷贝的文件名及其路径 容器名：要拷贝到容器里面对应的路径 1docker cp /home/wzd/application.properties nacos:/home/nacos/conf/application.properties 修改 application.properties,内容如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# springserver.servlet.contextPath=$&#123;SERVER_SERVLET_CONTEXTPATH:/nacos&#125;server.contextPath=/nacosserver.error.include-message=ALWAYSserver.port=8848spring.datasource.platform=mysqlnacos.cmdb.dumpTaskInterval=3600nacos.cmdb.eventTaskInterval=10nacos.cmdb.labelTaskInterval=300nacos.cmdb.loadDataAtStart=falsedb.num=1db.url.0=jdbc:mysql://192.168.130.128:3305/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useSSL=false&amp;allowPublicKeyRetrieval=truedb.user=nacosdb.password=123456### The auth system to use, currently only &#x27;nacos&#x27; is supported:nacos.core.auth.system.type=nacos### The token expiration in seconds:nacos.core.auth.default.token.expire.seconds=18000### The default token:# 注意：nacos v1.4.7是开启鉴权的，所以需要在application.properties中的配置信息。# 在application.properties找到nacos.core.auth.default.token.secret.key，# 默认情况下nacos.core.auth.default.token.secret.key是没有值得，所以导致启动nacos后报上面的错，# 根据官网说的，需要在启动nacos前给nacos.core.auth.default.token.secret.key填个256bit的token值，# 也可以复制官网上给的默认token值，SecretKey012345678901234567890123456789012345678901234567890123456789，这样问题就解决了。nacos.core.auth.default.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789### Turn on/off caching of auth information. By turning on this switch, the update of auth information would have a 15 seconds delay.nacos.core.auth.caching.enabled=falsenacos.core.auth.enable.userAgentAuthWhite=falsenacos.core.auth.server.identity.key=nacos.core.auth.server.identity.value=server.tomcat.accesslog.enabled=falseserver.tomcat.accesslog.pattern=%h %l %u %t &quot;%r&quot; %s %b %D# default current work dirserver.tomcat.basedir=file:.## spring security config### turn off securitynacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**# metrics for elastic searchmanagement.metrics.export.elastic.enabled=falsemanagement.metrics.export.influx.enabled=falsenacos.naming.distro.taskDispatchThreadCount=10nacos.naming.distro.taskDispatchPeriod=200nacos.naming.distro.batchSyncKeyCount=1000nacos.naming.distro.initDataRatio=0.9nacos.naming.distro.syncRetryDelay=5000nacos.naming.data.warmup=true 步骤 4：重新启动 Nacos 容器修改完配置文件后，需要重新启动 Nacos 容器。可以使用以下命令停止并删除之前的容器： 1docker stop nacos &amp;&amp; docker rm nacos 重新启动容器 12345678910docker run --name nacos -d \\-p 8848:8848 \\--network nacos_network \\-e MODE=standalone \\-e SPRING_DATASOURCE_PLATFORM=mysql \\-e MYSQL_SERVICE_HOST=192.168.130.128 \\-e MYSQL_SERVICE_DB_NAME=nacos \\-e MYSQL_SERVICE_USER=nacos \\-e MYSQL_SERVICE_PASSWORD=nacos \\nacos/nacos-server:v1.4.7 访问 http://192.168.130.128:8848/nacos，账号密码分别为nacos和nacos,即可登录 注意：在第二次启动nacos时，一直提示数据库连接不上，经过测试，数据库连接是通的，本地数据库连接工具也能正常连接，此时，这里需要注意的是如果你直接修改了示例文件中的配置文件，需要将# 号后面的 空格去掉，否则就回阴沟里帆船了。","categories":[{"name":"docker","slug":"docker","permalink":"http://example.com/categories/docker/"},{"name":"nacos","slug":"docker/nacos","permalink":"http://example.com/categories/docker/nacos/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"nacos","slug":"nacos","permalink":"http://example.com/tags/nacos/"}]},{"title":"docker启动redis","slug":"docker启动redis","date":"2024-08-06T01:03:48.000Z","updated":"2025-01-29T07:43:37.653Z","comments":true,"path":"2024/08/06/docker启动redis/","permalink":"http://example.com/2024/08/06/docker%E5%90%AF%E5%8A%A8redis/","excerpt":"docker启动redis1、拉取redis1docker pull redis:latest 当前最新版本为7.2.4","text":"docker启动redis1、拉取redis1docker pull redis:latest 当前最新版本为7.2.4 2、创建挂载目录12mkdir /home/wzd/redismkdir /home/wzd/redis/data 3、下载 redis.conf 文件1wget http://download.redis.io/redis-stable/redis.conf 注意：配置文件的版本需要和 redis 的版本对应，当前 redis 版本为7.2.4，配置文件的版本也应该为7.2.x,文件地址： https://redis.io/docs/latest/operate/oss_and_stack/management/config/ 4、设置权限1chmod 777 redis.conf 5、设置默认配置信息1vi /home/wzd/redis/redis.conf 12345bind 127.0.0.1 # 这行要注释掉，解除本地连接限制protected-mode no # 默认yes，如果设置为yes，则只允许在本机的回环连接，其他机器无法连接。daemonize no # 默认no 为不守护进程模式，docker部署不需要改为yes，docker run -d本身就是后台启动，不然会冲突requirepass 123456 # 设置密码appendonly yes # 持久化 6、docker 启动 redis1234567891011docker run \\-itd \\--name redis7.2.4 \\--privileged=true \\-p 6379:6379 \\-v /home/wzd/redis/redis.conf:/etc/redis/redis.conf \\-v /home/wzd/redis/data:/data \\redis:latest \\redis-server /etc/redis/redis.conf \\--appendonly yes \\--requirepass 123456 参数说明： 1234567891011121314docker run-itd -d 在后台运行容器，并且打印容器id。 -i 即使没有连接，也要保持标准输入保持打开状态，一般与 -t 连用。 -t 分配一个伪tty，一般与 -i 连用。--name redis7.2.4 容器名字--privileged=true 容器内的root拥有真正root权限，否则容器内root只是外部普通用户权限-p 6379:6379 把容器内的6379端口映射到宿主机6379端口-v /home/wzd/redis/redis.conf:/etc/redis/redis.conf 把宿主机配置好的redis.conf放到容器内的这个位置中(文件)-v /home/wzd/redis/data:/data 把redis持久化的数据在宿主机内显示，做数据备份redis:latest 镜像名字redis-server /etc/redis/redis.conf 这个是关键配置，让redis不是无配置启动，而是按照这个redis.conf的 配置启动--appendonly yes 开启数据持久化--requirepass 123456 密码 注意：启动 redis 需要添加 –privileged&#x3D;true 命令，否则无法启动 7、在 docker 中打开 redis 客户端1、首先交互方式进入 redis 容器1docker exec -it [容器ID] /bin/bash 2、随后运行客户端1redis-cli 3、执行客户端命令12127.0.0.1:6379&gt; get keys(error) NOAUTH Authentication required. 出现该情况，输入密码即可 123auth &#x27;123456&#x27;auth 123456#两种命令都可以","categories":[{"name":"docker","slug":"docker","permalink":"http://example.com/categories/docker/"},{"name":"redis","slug":"docker/redis","permalink":"http://example.com/categories/docker/redis/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"}]},{"title":"docker安装nginx","slug":"docker安装nginx","date":"2024-08-06T01:03:24.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/08/06/docker安装nginx/","permalink":"http://example.com/2024/08/06/docker%E5%AE%89%E8%A3%85nginx/","excerpt":"docker安装nignx1、拉取nginx镜像1docker pull nginx:latest","text":"docker安装nignx1、拉取nginx镜像1docker pull nginx:latest 2、创建Nginx配置文件12345678启动前需要先创建Nginx外部挂载的配置文件（ /home/wzd/nginx/conf/nginx.conf）之所以要先创建 , 是因为Nginx本身容器只存在/etc/nginx 目录 , 本身就不创建 nginx.conf 文件当服务器和容器都不存在 nginx.conf 文件时, 执行启动命令的时候 docker会将nginx.conf 作为目录创建 , 这并不是我们想要的结果 。# 创建挂载目录mkdir -p /home/wzd/nginx/confmkdir -p /home/wzd/nginx/logmkdir -p /home/wzd/nginx/html 3、创建容器并运行​ Docker 创建Nginx容器 1234567891011121314151617181920# 生成容器docker run --name nginx -p 9001:80 -d nginx#容器中的nginx.conf文件和conf.d文件夹复制到宿主机# 将容器nginx.conf文件复制到宿主机docker cp nginx:/etc/nginx/nginx.conf /home/wzd/nginx/conf/nginx.conf# 将容器conf.d文件夹下内容复制到宿主机docker cp nginx:/etc/nginx/conf.d /home/wzd/nginx/conf/conf.d# 将容器中的html文件夹复制到宿主机docker cp nginx:/usr/share/nginx/html /home/wzd/nginx/# 直接执行docker rm nginx或者以容器id方式关闭容器# 找到nginx对应的容器iddocker ps -a# 关闭该容器docker stop nginx# 删除该容器docker rm nginx # 删除正在运行的nginx容器docker rm -f nginx 4、重新启动容器12345678docker run \\-p 9002:80 \\--name nginx \\-v /home/wzd/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \\-v /home/wzd/nginx/conf/conf.d:/etc/nginx/conf.d \\-v /home/wzd/nginx/log:/var/log/nginx \\-v /home/wzd/nginx/html:/usr/share/nginx/html \\-d nginx:latest 参数注释： 命令 描述 –name nginx 启动容器的名字 -d 后台运行 -p 9002:80 将容器的 80(后面那个) 端口映射到主机的 9002(前面那个) 端口 -v &#x2F;home&#x2F;nginx&#x2F;conf&#x2F;nginx.conf:&#x2F;etc&#x2F;nginx&#x2F;nginx.conf 挂载nginx.conf配置文件 -v &#x2F;home&#x2F;nginx&#x2F;conf&#x2F;conf.d:&#x2F;etc&#x2F;nginx&#x2F;conf.d 挂载nginx配置文件 -v &#x2F;home&#x2F;nginx&#x2F;log:&#x2F;var&#x2F;log&#x2F;nginx 挂载nginx日志文件 -v &#x2F;home&#x2F;nginx&#x2F;html:&#x2F;usr&#x2F;share&#x2F;nginx&#x2F;html 挂载nginx内容 nginx:latest 本地运行的版本 \\ shell 命令换行 ​ 注意：-p 9002:80 ，将 容器的80端口映射到 docker 所在服务器（虚拟机）的 9002 端口，此时虚拟机的9002端口并没有在防火墙中开启，但是虚拟机外的网络依旧能访问到9002端口,是因为docker 容器创建时，如果指定了容器映射的宿主机端口（9002），docker就会在 iptables 的规则链中加上自己容器对外提供服务所需的规则链，所以docker 容器跑的服务，虚拟机所在的主机（本地电脑）可以访问到！ 单行模式 12345678docker run \\ -p 9002:80 \\--name nginx \\-v /home/wzd/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \\-v /home/wzd/nginx/conf/conf.d:/etc/nginx/conf.d \\-v /home/wzd/nginx/log:/var/log/nginx \\-v /home/wzd/nginx/html:/usr/share/nginx/html \\-d nginx:latest","categories":[{"name":"docker","slug":"docker","permalink":"http://example.com/categories/docker/"},{"name":"nginx","slug":"docker/nginx","permalink":"http://example.com/categories/docker/nginx/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"http://example.com/tags/nginx/"}]},{"title":"docker安装Mysql 8.0.11","slug":"docker安装Mysql-8-0-11","date":"2024-08-06T01:03:09.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/08/06/docker安装Mysql-8-0-11/","permalink":"http://example.com/2024/08/06/docker%E5%AE%89%E8%A3%85Mysql-8-0-11/","excerpt":"docker安装Mysql 8.0.111、下载镜像1docker pull mysql:8.0.11","text":"docker安装Mysql 8.0.111、下载镜像1docker pull mysql:8.0.11 2、创建挂载目录​ 使用 -p 创建多级目录，即 &#x2F;home目录下创建 mysql 目录， mysql 目录下又创建 log 、data 、conf 三个目录 123mkdir -p /home/mountDirectory/mysql-8.0.1/logsmkdir -p /home/mountDirectory/mysql-8.0.1/datamkdir -p /home/mountDirectory/mysql-8.0.1/conf 3、创建my.cnf 配置文件​ MySQL默认配置文件 &#x2F;etc&#x2F;my.cnf 末尾中有这么一行：!includedir &#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F; ，意思是，在 &#x2F;etc&#x2F;mysql&#x2F;conf.d&#x2F; 目录下新建自定义的配置文件 my.cnf也会被读取到，而且还是优先读取的（Docker Hub中的MySQL教程文档）,进入 &#x2F;etc目录下创建。 1touch my.cnf 将一下内容写入到 my.cnf 配置文件中 12345678[mysqld]init-connect=&quot;SET collation_connection=utf8mb4_0900_ai_ci&quot;init_connect=&quot;SET NAMES utf8mb4&quot;skip-character-set-client-handshakedefault_authentication_plugin=mysql_native_passwordsql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_ENGINE_SUBSTITUTION#mysql不区分表名大小写lower_case_table_names=1 4、创建容器将配置选项作为标志传递给mysqld，MYSQL_ROOT_PASSWORD 指定密码 1234567891011docker run --name mysql8 \\-v /home/mountDirectory/mysql-8.0.11/logs:/var/log/mysql \\-v /home/mountDirectory/mysql-8.0.11/data:/var/lib/mysql \\-v /home/mountDirectory/mysql-8.0.11/conf:/etc/mysql/conf.d \\-p 3305:3306 \\-e MYSQL_ROOT_PASSWORD=123456 \\--restart=always \\-d mysql:8.0.11 \\--init-connect=&quot;SET collation_connection=utf8mb4_0900_ai_ci&quot; \\--init-connect=&quot;SET NAMES utf8mb4&quot; \\--skip-character-set-client-handshake 5、使用 DataGrip 连接连接 url 如下 12```mysqljdbc:mysql://ip地址:端口号/mysql?useSSL=no&amp;allowPublicKeyRetrieval=true","categories":[{"name":"docker","slug":"docker","permalink":"http://example.com/categories/docker/"},{"name":"mysql","slug":"docker/mysql","permalink":"http://example.com/categories/docker/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"}]},{"title":"docker 安装 zookeeper","slug":"docker-安装-zookeeper","date":"2024-08-06T01:02:45.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/08/06/docker-安装-zookeeper/","permalink":"http://example.com/2024/08/06/docker-%E5%AE%89%E8%A3%85-zookeeper/","excerpt":"docker 安装 zookeeper1、下载镜像1docker pull zookeeper:3.9.1","text":"docker 安装 zookeeper1、下载镜像1docker pull zookeeper:3.9.1 2、配置挂载目录​ 在 &#x2F;home&#x2F;mountDirectory&#x2F; 目录下新增 文件夹 zookeeper，在 zookeeper 目录下新增 data 目录。 3、启动容器1docker run -d -e TZ=&quot;Asia/Shanghai&quot; -p 2181:2181 -v /home/mountDirectory/zookeeper/data:/data --name zookeeper --restart always zookeeper:3.9.1 参数注释： 参数 释义 -e TZ&#x3D;”Asia&#x2F;Shanghai” 指定上海时区 -d 表示在一直在后台运行容器 -p 2181:2181 对端口进行映射，将本地2181端口映射到容器内部的2181端口 –name 设置创建的容器名称 -v 将本地目录(文件)挂载到容器指定目录 –restart always #始终重新启动zookeeper 4、测试1docker exec -it zookeeper /bin/bash 进入容器内，然后进入 bin目录，使用 .&#x2F;zkCli.sh 命令启动客户端。","categories":[{"name":"docker","slug":"docker","permalink":"http://example.com/categories/docker/"},{"name":"zookeeper","slug":"docker/zookeeper","permalink":"http://example.com/categories/docker/zookeeper/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://example.com/tags/zookeeper/"}]},{"title":"centos8防火墙相关指令","slug":"centos8防火墙相关指令","date":"2024-08-06T00:54:56.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/08/06/centos8防火墙相关指令/","permalink":"http://example.com/2024/08/06/centos8%E9%98%B2%E7%81%AB%E5%A2%99%E7%9B%B8%E5%85%B3%E6%8C%87%E4%BB%A4/","excerpt":"CentOs8防火墙操作命令查看防火墙某个端口是否开放1firewall-cmd --query-port=6379/tcp","text":"CentOs8防火墙操作命令查看防火墙某个端口是否开放1firewall-cmd --query-port=6379/tcp 开放防火墙端口1firewall-cmd --zone=public --add-port=6379/tcp --permanent 关闭端口1firewall-cmd --zone=public --remove-port=6379/tcp --permanent 重新载入配置，让开放或关闭的端口配置生效1firewall-cmd --reload 查看防火墙状态1systemctl status firewalld 关闭防火墙1systemctl stop firewalld 打开防火墙1systemctl start firewalld 重启防火墙1systemctl restart firewalld 开放一段端口1firewall-cmd --zone=public --add-port=40000-45000/tcp --permanent 查看开放的端口列表1firewall-cmd --zone=public --list-ports","categories":[{"name":"centos8","slug":"centos8","permalink":"http://example.com/categories/centos8/"},{"name":"firewall","slug":"centos8/firewall","permalink":"http://example.com/categories/centos8/firewall/"}],"tags":[{"name":"centos8","slug":"centos8","permalink":"http://example.com/tags/centos8/"},{"name":"firewall","slug":"firewall","permalink":"http://example.com/tags/firewall/"}]},{"title":"nacos集群部署","slug":"nacos集群部署","date":"2024-07-27T12:01:18.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/07/27/nacos集群部署/","permalink":"http://example.com/2024/07/27/nacos%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/","excerpt":"本文主要介绍在Centos8 系统中部署 nacos2.2.1集群。","text":"本文主要介绍在Centos8 系统中部署 nacos2.2.1集群。 一、环境准备1.1、版本说明 组件 版本 备注 Centos CentOS Linux release 8.4.2105 请自行搜索安装 Nacos 2.2.1 Mysql 8.0.37 请自行搜索安装 openjdk 1.8.0_312-b07 请自行搜索配置 1.2、服务部署规划 主机名 IP 部署端口 路径 说明 Centos8 173.16.4.130 8848 &#x2F;opt&#x2F;nacos nacos1 Centos8(2) 173.16.4.131 8848 &#x2F;opt&#x2F;nacos nacos2 Centos8(3) 173.16.4.132 8848 &#x2F;opt&#x2F;nacos Nacos3 Mac 127.0.0.1 3305 ～ 本人在mac电脑中使用docker部署了mysql，端口为3305 二、部署安装2.1、下载并解压​ 下载 nacos-server-2.2.1.tar.gz ，将压缩包拷贝到服务器中并解压。 123456[root@centos8 /]# cd /opt/nacos/[root@centos8 nacos]# lsnacos-server-2.2.1.tar.gz[root@centos8 nacos]# tar -zxvf nacos-server-2.2.1.tar.gz[root@centos8 nacos]# ls[root@centos8 nacos]# nacos nacos-server-2.2.1.tar.gz 2.2、配置​ 集群配置 ​ 进入 nacos 的 conf 目录，将 cluster.conf.example 拷贝一份，并对 cluster.conf 进行编辑。 12345678910111213[root@centos8 nacos]# cd nacos/conf/[root@centos8 conf]# cp cluster.conf.example cluster.conf[root@centos8 conf]# ll-rw-r--r--. 1 502 games 1224 3月 13 2023 1.4.0-ipv6_support-update.sql-rw-r--r--. 1 502 games 10900 7月 27 21:46 application.properties-rw-r--r--. 1 502 games 9435 3月 17 2023 application.properties.example-rw-r--r--. 1 root root 79 7月 27 21:47 cluster.conf-rw-r--r--. 1 502 games 670 3月 17 2023 cluster.conf.example-rw-r--r--. 1 502 games 8939 3月 17 2023 derby-schema.sql-rw-r--r--. 1 502 games 10825 3月 17 2023 mysql-schema.sql-rw-r--r--. 1 502 games 31156 3月 17 2023 nacos-logback.xml[root@centos8 conf]# vim cluster.conf ​ 修改内容如下： 1234#2024-07-27T21:47:11.817173.16.4.130:8848173.16.4.131:8848173.16.4.132:8848 ​ 这里是我们在服务器上运行的三台 nacos 服务实力，IP 地址就是 步骤 1.2 的三个地址。端口号为步骤 1.2 的三个端口号。 ​ 文件属性配置 ​ 文件属性配置主要修改 application.properties 文件。 1[root@centos8 conf]# vim application.properties ​ 数据源配置： 12345678910111213141516171819#*************** Config Module Related Configurations ***************#### If use MySQL as datasource:### Deprecated configuration property, it is recommended to use `spring.sql.init.platform` replaced.spring.datasource.platform=mysql#spring.sql.init.platform=mysql### Count of DB:db.num=1### Connect URL of DB:db.url.0=jdbc:mysql://192.168.15.89:3305/nacos?characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useUnicode=true&amp;useSSL=false&amp;serverTimezone=UTCdb.user=rootdb.password=123456### Connection pool configuration: hikariCPdb.pool.config.connectionTimeout=30000db.pool.config.validationTimeout=10000db.pool.config.maximumPoolSize=20db.pool.config.minimumIdle=2 ​ 鉴权配置： ​ nacos 提供鉴权实现，我们需要开启鉴权，同时自定义用于生成 JWT 令牌的密钥。1.4.1 版本开始，nacos添加服务身份识别功能，用户可以自己配置服务端的 identity， 不再使用 userAgent 作为服务端请求的判断标准。 ​ 配置信息如下： 12345678910111213### The auth system to use, currently only &#x27;nacos&#x27; and &#x27;ldap&#x27; is supported:nacos.core.auth.system.type=nacos### If turn on auth system:nacos.core.auth.enabled=true### Since 1.4.1, worked when nacos.core.auth.enabled=true and nacos.core.auth.enable.userAgentAuthWhite=false.### The two properties is the white list for auth and used by identity the request from other server.nacos.core.auth.server.identity.key=nacosnacos.core.auth.server.identity.value=nacos### The default token (Base64 String):nacos.core.auth.plugin.nacos.token.secret.key=U2VjcmV0S2V5aGFma3NhZmtkYWtma2FrZmFranNkZml3dWJzZGZhc2RmYXNkZiA= ​ 注意：集群中的所有配置文件都要配置相同的 server.identity 信息，否则可能导致服务端之间数据不一致或无法删除实例等问题。具具体可以参考 https://nacos.io/zh-cn/docs/v2/guide/user/auth.html 开启服务身份识别功能模块。 ​ 启动之前防火墙需要放开端口 8848，8849 和 9848。 2.3、启动​ 进入 bin 目录，启动nacos。 1234[root@centos8 bin]# ./startup.sh /usr/lib/jvm/java-1.8.0-openjdk/bin/java -Djava.ext.dirs=/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext:/usr/lib/jvm/java-1.8.0-openjdk/lib/ext -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/nacos/nacos/logs/java_heapdump.hprof -XX:-UseLargePages -Dnacos.member.list= -Xloggc:/opt/nacos/nacos/logs/nacos_gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Dloader.path=/opt/nacos/nacos/plugins,/opt/nacos/nacos/plugins/health,/opt/nacos/nacos/plugins/cmdb,/opt/nacos/nacos/plugins/selector -Dnacos.home=/opt/nacos/nacos -jar /opt/nacos/nacos/target/nacos-server.jar --spring.config.additional-location=file:/opt/nacos/nacos/conf/ --logging.config=/opt/nacos/nacos/conf/nacos-logback.xml --server.max-http-header-size=524288nacos is starting with clusternacos is starting，you can check the /opt/nacos/nacos/logs/start.out 查看启动日志： 12345678910111213141516171819202122[root@centos8 logs]# cd /opt/nacos/nacos/logs/[root@centos8 logs]# tail -2000f start.out /usr/lib/jvm/java-1.8.0-openjdk/bin/java -Djava.ext.dirs=/usr/lib/jvm/java-1.8.0-openjdk/jre/lib/ext:/usr/lib/jvm/java-1.8.0-openjdk/lib/ext -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize=128m -XX:MaxMetaspaceSize=320m -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/opt/nacos/nacos/logs/java_heapdump.hprof -XX:-UseLargePages -Dnacos.member.list= -Xloggc:/opt/nacos/nacos/logs/nacos_gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=100M -Dloader.path=/opt/nacos/nacos/plugins,/opt/nacos/nacos/plugins/health,/opt/nacos/nacos/plugins/cmdb,/opt/nacos/nacos/plugins/selector -Dnacos.home=/opt/nacos/nacos -jar /opt/nacos/nacos/target/nacos-server.jar --spring.config.additional-location=file:/opt/nacos/nacos/conf/ --logging.config=/opt/nacos/nacos/conf/nacos-logback.xml --server.max-http-header-size=524288 ,--. ,--.&#x27;| ,--,: : | Nacos 2.2.1,`--.&#x27;`| &#x27; : ,---. Running in cluster mode, All function modules| : : | | &#x27; ,&#x27;\\ .--.--. Port: 8848: | \\ | : ,--.--. ,---. / / | / / &#x27; Pid: 7398| : &#x27; &#x27;; | / \\ / \\. ; ,. :| : /`./ Console: http://173.16.4.130:8848/nacos/index.html&#x27; &#x27; ;. ;.--. .-. | / / &#x27;&#x27; | |: :| : ;_| | | \\ | \\__\\/: . .. &#x27; / &#x27; | .; : \\ \\ `. https://nacos.io&#x27; : | ; .&#x27; ,&quot; .--.; |&#x27; ; :__| : | `----. \\| | &#x27;`--&#x27; / / ,. |&#x27; | &#x27;.&#x27;|\\ \\ / / /`--&#x27; /&#x27; : | ; : .&#x27; \\ : : `----&#x27; &#x27;--&#x27;. /; |.&#x27; | , .-./\\ \\ / `--&#x27;---&#x27;&#x27;---&#x27; `--`---&#x27; `----&#x27;2024-07-27 23:10:56,152 INFO The server IP list of Nacos is [173.16.4.130:8848, 173.16.4.131:8848, 173.16.4.132:8848]2024-07-27 23:10:57,153 INFO Nacos is starting... ​ nacos 以集群方式启动，登陆控制台 （http://173.16.4.130:8848/nacos/index.htm），如下图: 按照上述操作启动其他两台 nacos，当启动其他的 nacos 服务时，节点状态会从 DOWN 变为 UP。 三、增加systemd管理3.1、 编写启动文件1[root@centos8 ~]# vim /etc/systemd/system/nacos.service 3.2、在文件中写入以下内容12345678910111213[Unit]Description=nacosAfter=network.target[Service]Type=forkingExecStart=/opt/nacos/nacos/bin/startup.shExecReload=/opt/nacos/bacos/bin/shutdown.shExecStop=/opt/nacos/bin/shutdown.shPrivateTmp=true[Install]WantedBy=multi-user.target ​ 其中 &#x2F;opt&#x2F;nacos 为本机按照的 nacos 文件路径，-m standalone，表示作为单机启动，不加代表以集群启动，此处以集群启动。 3.3、设置开机启动123456789101112# 重启守护现场，进行文件生效配置[root@centos8 ~]# systemctl daemon-reload# 设置为开机启动[root@centos8 ~]# systemctl enable nacos.service# 启动 nacos 服务[root@centos8 ~]# systemctl start nacos.service# 停止 nacos 服务[root@centos8 ~]# systemctl stop nacos.service # 重启服务器[root@centos8 ~]# reboot # 查看 nacos 状态[root@centos8 ~]# systemctl status nacos.service","categories":[{"name":"nacos","slug":"nacos","permalink":"http://example.com/categories/nacos/"}],"tags":[{"name":"nacos","slug":"nacos","permalink":"http://example.com/tags/nacos/"},{"name":"原创","slug":"原创","permalink":"http://example.com/tags/%E5%8E%9F%E5%88%9B/"}]},{"title":"zookeeper集群搭建","slug":"zookeeper集群搭建","date":"2024-07-25T12:15:42.000Z","updated":"2025-01-29T06:14:53.730Z","comments":true,"path":"2024/07/25/zookeeper集群搭建/","permalink":"http://example.com/2024/07/25/zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/","excerpt":"本文主要讲述如何在 centos8 上搭建 zookeeper 集群。centos8 基础知识自行搜索，本文不过多赘述。 1、准备工作​ 配置 idk环境，本文为 jdk1.8，下载 SSH 连接工具，本文使用 tabby。准备 三台 服务器，也可以一台，在同时启动三个 zookeeper（伪集群）。本文用三台服务器作为案例，ip 地址分别为 173.16.4.130，173.16.4.131，173.16.4.131。","text":"本文主要讲述如何在 centos8 上搭建 zookeeper 集群。centos8 基础知识自行搜索，本文不过多赘述。 1、准备工作​ 配置 idk环境，本文为 jdk1.8，下载 SSH 连接工具，本文使用 tabby。准备 三台 服务器，也可以一台，在同时启动三个 zookeeper（伪集群）。本文用三台服务器作为案例，ip 地址分别为 173.16.4.130，173.16.4.131，173.16.4.131。 2、下载 zookeeper并解压1wget https://dlcdn.apache.org/zookeeper/zookeeper-3.8.4/apache-zookeeper-3.8.4-bin.tar.gz 3、解压123tar -zxvf apache-zookeeper-3.8.4-bin.tar.gzz -c /opt/zookeepercd /opt/zookeeper/mv apache-zookeeper-3.8.4-bin apache-zookeeper-3.8.4 4、zookeeper 配置（重要）4.1、进入 conf 目录，新增 data 和 log 文件夹12345cd /opt/zookeeper/apache-zookeeper-3.8.4/confmkdir datamkdir loglsconfiguration.xsl data log logback.xml zoo_sample.cfg 4.2、配置 zookeeper 配置文件123cp zoo_sample.cfg zoo.cfglsconfiguration.xsl data logback.xml zoo.cfg zoo_sample.cfg 1vim zoo.cfg 将文件配置成如下内容： 123456789101112131415161718192021222324252627282930313233343536373839404142# The number of milliseconds of each ticktickTime=2000# The number of ticks that the initial # synchronization phase can takeinitLimit=10# The number of ticks that can pass between # sending a request and getting an acknowledgementsyncLimit=5# the directory where the snapshot is stored.# do not use /tmp for storage, /tmp here is just # example sakes.dataDir=/opt/zookeeper/apache-zookeeper-3.8.4/conf/datadataLogDir=/opt/zookeeper/apache-zookeeper-3.8.4/conf/log# the port at which the clients will connectclientPort=2181# the maximum number of client connections.# increase this if you need to handle more clients#maxClientCnxns=60## Be sure to read the maintenance section of the # administrator guide before turning on autopurge.## https://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance## The number of snapshots to retain in dataDir#autopurge.snapRetainCount=3# Purge task interval in hours# Set to &quot;0&quot; to disable auto purge feature#autopurge.purgeInterval=1## Metrics Providers## https://prometheus.io Metrics Exporter#metricsProvider.className=org.apache.zookeeper.metrics.prometheus.PrometheusMetricsProvider#metricsProvider.httpHost=0.0.0.0#metricsProvider.httpPort=7000#metricsProvider.exportJvmInfo=true# 添加如下内容 server.x=A:B:Cserver.1=173.16.4.130:2888:3888server.2=173.16.4.131:2888:3888server.3=173.16.4.132:2888:3888 参数介绍： 属性 注释 tickTime 在运行过程中，Leader负责与ZK集群中所有机器进行通信，例如通过一些心跳检测机制，来检测机器的存活状态。如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了。注意：不要把这个参数设置得过大，否则可能会掩盖一些问题。 initLimit Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态。Leader允许 Follower 在 initLimit 时间内完成这个工作。通常情况下，我们不用太在意这个参数的设置。如果ZK集群的数据量确实很大了，F在启动的时候，从Leader上同步数据的时间也会相应变长，因此在这种情况下，有必要适当调大这个参数了。 syncLimit 有 5 （可配置）台机器可以同时运转。 dataDir 4.1 步骤中新增的 data 的路径。存储快照文件snapshot的目录。默认情况下，事务日志也会存储在这里。建议同时配置参数dataLogDir, 事务日志的写性能直接影响zk性能。 clientPort 客户端连接server的端口，即对外服务端口，一般设置为2181。 server.1&#x3D;173.16.4.130:2888:3888 第一台服务器 IP 地址 server.2&#x3D;173.16.4.131:2888:3888 第二台服务器 IP 地址 server.3&#x3D;173.16.4.132:2888:3888 第三台服务器 IP 地址 server.x&#x3D;[hostname]:nnnnn[:nnnnn] 这里的x是一个数字，与myid文件中的id是一致的。右边可以配置两个端口，第一个端口用于F和L之间的数据同步和其它通信，第二个端口用于Leader选举过程中投票通信。 ​ 注意： 2888 是Zookeeper 集群中服务器之间通信的端口，用于数据同步。3888 是Zookeeper 选举的端口，用于集群领导者选举时的通信。Zookeeper 集群中的 2888 和 3888 端口是可以修改的。你可以在 zoo.cfg 配置文件中更改这些端口，只需要确保所有节点的配置文件中的端口设置保持一致，并且新的端口没有被其他应用程序占用。 ​ 确保每个节点（每台服务器）上的防火墙允许 Zookeeper 使用的端口（2181, 2888, 3888）。 ​ 开放防火墙端口 1firewall-cmd --zone=public --add-port=2181/tcp --permanent ​ 重启防火墙 1systemctl status firewalld ​ 查看防火墙开放的端口 1firewall-cmd --zone=public --list-ports 4.3、配置 myid 文件 （重要）​ 在每台服务器上执行如下命令： 12cd /opt/zookeeper/apache-zookeeper-3.8.4/conf/dataecho &quot;1&quot; &gt; myid ​ 注意， echo “1” 中的数字，这个数字和 zoo.cfg 中配置的 server.x&#x3D;A:B:C 相同，根据各自的 ip 进行配置, 比如 173.16.4.130 配置的数字是1，173.16.4.131 配置的数字是2。 5、启动zookeeper1234567891011121314151617181920212223242526272829#173.16.4.130[root@centos8 conf]# cd /opt/zookeeper/apache-zookeeper-3.8.4/bin/[root@centos8 bin]# ./zkServer.sh start /opt/zookeeper/apache-zookeeper-3.8.4/conf/zoo.cfg ..启动内容省略...[root@centos8 bin]# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper/apache-zookeeper-3.8.4/bin/../conf/zoo.cfgClient port found: 2181. Client address: localhost. Client SSL: false.Mode: follower#173.16.4.131[root@centos8 conf]# cd /opt/zookeeper/apache-zookeeper-3.8.4/bin/[root@centos8 bin]# ./zkServer.sh start /opt/zookeeper/apache-zookeeper-3.8.4/conf/zoo.cfg ..启动内容省略...[root@centos8 bin]# ./zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper/apache-zookeeper-3.8.4/bin/../conf/zoo.cfgClient port found: 2182. Client address: localhost. Client SSL: false.Mode: leader#173.16.4.132[root@centos8 conf]# cd /opt/zookeeper/apache-zookeeper-3.8.4/bin/[root@centos8 bin]# ./zkServer.sh start /opt/zookeeper/apache-zookeeper-3.8.4/conf/zoo.cfg ..启动内容省略..../zkServer.sh statusZooKeeper JMX enabled by defaultUsing config: /opt/zookeeper/apache-zookeeper-3.8.4/bin/../conf/zoo.cfgClient port found: 2183. Client address: localhost. Client SSL: false.Mode: follower 参数 注释 Mode: follower 跟随者。 Mode: leader 领导者。 6、集群角色​ Leader：领导者 ​ 事物请求（写操作）的唯一调度者和处理者，保证集群事务处理的顺序性；集群内部各个服务器的调度者。对于 create、setData、delete 等有写操作的请求，则统一转发给 leader 处理，leader 需要决定编号、执行操作，这个过程称为事物。 ​ Follower： 跟随者 ​ 处理客户端非事物（读操作）请求（可以直接响应），转发事物请求给 Leader ；参与集群 Leader 选举投票。 ​ Observer: 观察者 ​ 对于非事物请求可以独立处理（读操作），对于事物请求会转发给 Leader 处理， Observer 节点接收来自 Leader 的 inform 信息，更新自己本地的缓存，不参与提交和选举投票。通常在不影响集群事务处理能力的前提下提升集群的非事物处理能力。 7、增加systemd管理zookeeper功能7.1、新建 service 文件1[root@centos8 /]# vim /etc/systemd/system/zookeeper.service ​ 在文件中新增以下内容： 123456789101112[Unit]Description=zookeeper.serviceAfter=network.targetConditionPathExists=/opt/zookeeper/apache-zookeeper-3.8.4/conf/zoo.cfg[Service]Type=forkingUser=rootGroup=rootExecStart=/opt/zookeeper/apache-zookeeper-3.8.4/bin/zkServer.sh startExecStop=/opt/zookeeper/apache-zookeeper-3.8.4/bin/zkServer.sh stop[Install]WantedBy=multi-user.target ​ 执行以下命令重启守护线程： 1[root@centos8 /]# systemctl daemon-reload 7.2、修改 zkEnv.sh 文件​ 直接使用systemctl启动zookeeper会因找不到java的路径报错，我们需要手动修改 zkEnv.sh 文件： 1[root@centos8 /]# vim /opt/zookeeper/apache-zookeeper-3.8.4/bin/zkEnv.sh ​ 编辑如下内容： 12345#添加如下一行JAVA_HOME=/usr/lib/jvm/java#到此两行上方即可:ZOOBINDIR=&quot;$&#123;ZOOBINDIR:-/usr/bin&#125;&quot;ZOOKEEPER_PREFIX=&quot;$&#123;ZOOBINDIR&#125;/..&quot; 7.3、启动和停止12[root@localhost conf]# systemctl start zookeeper[root@localhost conf]# systemctl stop zookeeper 8、开机自启​ 执行以下命令： 1[root@localhost conf]# systemctl enable zookeeper","categories":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://example.com/categories/zookeeper/"}],"tags":[{"name":"zookeeper","slug":"zookeeper","permalink":"http://example.com/tags/zookeeper/"},{"name":"原创","slug":"原创","permalink":"http://example.com/tags/%E5%8E%9F%E5%88%9B/"}]},{"title":"MySQL优化之EXPLAIN命令解析","slug":"MySQL优化之EXPLAIN命令解析","date":"2024-07-02T08:58:36.000Z","updated":"2025-01-29T06:14:53.728Z","comments":true,"path":"2024/07/02/MySQL优化之EXPLAIN命令解析/","permalink":"http://example.com/2024/07/02/MySQL%E4%BC%98%E5%8C%96%E4%B9%8BEXPLAIN%E5%91%BD%E4%BB%A4%E8%A7%A3%E6%9E%90/","excerpt":"MySQL优化之EXPLAIN命令解析​ 转自：https://juejin.cn/post/7073761727850119199 ​ EXPLAIN：查看SQL语句的执行计划 ​ EXPLAIN命令可以帮助我们深入了解MySQL基于开销的优化器，还可以获得很多可能被优化器考虑到的访问策略的细节，以及当运行SQL语句时哪种策略预计会被优化器采用，在优化慢查询时非常有用 ​ 执行explain之后结果集包含如下信息： 123+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------+ ​ 下面将对每一个值进行解释","text":"MySQL优化之EXPLAIN命令解析​ 转自：https://juejin.cn/post/7073761727850119199 ​ EXPLAIN：查看SQL语句的执行计划 ​ EXPLAIN命令可以帮助我们深入了解MySQL基于开销的优化器，还可以获得很多可能被优化器考虑到的访问策略的细节，以及当运行SQL语句时哪种策略预计会被优化器采用，在优化慢查询时非常有用 ​ 执行explain之后结果集包含如下信息： 123+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+-------+ ​ 下面将对每一个值进行解释 1、id​ id用来标识整个查询中SELELCT语句的顺序，在嵌套查询中id越大的语句越先执行，该值可能为NULL; id如果相同，从上往下依次执行。id不同，id值越大，执行优先级越高，如果行引用其他行的并集结果，则该值可以为NULL。 2、select_type​ select_type表示查询使用的类型，有下面几种： 2.1、simple​ 简单的select查询，没有union或者子查询 123456mysql&gt; explain select * from test where id = 1000;+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+| 1 | SIMPLE | test | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | NULL |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------+ 2.2、primary​ 最外层的select查询 1234567mysql&gt; explain select * from (select * from test where id = 1000) a;+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+| 1 | PRIMARY | &lt;derived2&gt; | system | NULL | NULL | NULL | NULL | 1 | NULL || 2 | DERIVED | test | const | PRIMARY | PRIMARY | 8 | const | 1 | NULL |+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+ 2.3、union​ union中的第二个或随后的select查询，不依赖于外部查询的结果集 12345678mysql&gt; explain select * from test where id = 1000 union all select * from test2 ;+----+--------------+------------+-------+---------------+---------+---------+-------+-------+-----------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+--------------+------------+-------+---------------+---------+---------+-------+-------+-----------------+| 1 | PRIMARY | test | const | PRIMARY | PRIMARY | 8 | const | 1 | NULL || 2 | UNION | test2 | ALL | NULL | NULL | NULL | NULL | 67993 | NULL || NULL | UNION RESULT | &lt;union1,2&gt; | ALL | NULL | NULL | NULL | NULL | NULL | Using temporary |+----+--------------+------------+-------+---------------+---------+---------+-------+-------+-----------------+ 2.4、dependent union​ union中的第二个或随后的select查询，依赖于外部查询的结果集 123456789mysql&gt; explain select * from test where id in (select id from test where id = 1000 union all select id from test2) ;+----+--------------------+------------+--------+---------------+---------+---------+-------+-------+-----------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+--------------------+------------+--------+---------------+---------+---------+-------+-------+-----------------+| 1 | PRIMARY | test | ALL | NULL | NULL | NULL | NULL | 68505 | Using where || 2 | DEPENDENT SUBQUERY | test | const | PRIMARY | PRIMARY | 8 | const | 1 | Using index || 3 | DEPENDENT UNION | test2 | eq_ref | PRIMARY | PRIMARY | 8 | func | 1 | Using index || NULL | UNION RESULT | &lt;union2,3&gt; | ALL | NULL | NULL | NULL | NULL | NULL | Using temporary |+----+--------------------+------------+--------+---------------+---------+---------+-------+-------+-----------------+ 2.5、subquery​ 子查询中的第一个 select 查询，不依赖与外部查询的结果集 12345678mysql&gt; explain select * from test where id = (select id from test where id = 1000);+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------------+| 1 | PRIMARY | test | const | PRIMARY | PRIMARY | 8 | const | 1 | NULL || 2 | SUBQUERY | test | const | PRIMARY | PRIMARY | 8 | const | 1 | Using index |+----+-------------+-------+-------+---------------+---------+---------+-------+------+-------------+ 2.6、dependent subquery​ 子查询中的第一个select查询，依赖于外部查询的结果集 123456789mysql&gt; explain select * from test where id in (select id from test where id = 1000 union all select id from test2) ;+----+--------------------+------------+--------+---------------+---------+---------+-------+-------+-----------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+--------------------+------------+--------+---------------+---------+---------+-------+-------+-----------------+| 1 | PRIMARY | test | ALL | NULL | NULL | NULL | NULL | 68505 | Using where || 2 | DEPENDENT SUBQUERY | test | const | PRIMARY | PRIMARY | 8 | const | 1 | Using index || 3 | DEPENDENT UNION | test2 | eq_ref | PRIMARY | PRIMARY | 8 | func | 1 | Using index || NULL | UNION RESULT | &lt;union2,3&gt; | ALL | NULL | NULL | NULL | NULL | NULL | Using temporary |+----+--------------------+------------+--------+---------------+---------+---------+-------+-------+-----------------+ 2.7、derived​ 用于from子句中有子查询的情况，mysql会递归执行这些子查询，此结果集放在临时表中 12345678mysql&gt; explain select * from (select * from test2 where id = 1000)a;+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+| 1 | PRIMARY | &lt;derived2&gt; | system | NULL | NULL | NULL | NULL | 1 | NULL || 2 | DERIVED | test2 | const | PRIMARY | PRIMARY | 8 | const | 1 | NULL |+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+ 3、table​ table用来表示输出行所引用的表名。 4、type（重要）​ type表示访问类型，下面一次解释各种类型，类型顺序从最好到最差排列。 4.1、system​ 表仅有一行，是 cons 类型的一个特例。因为子查询只有一行数据，模拟了单表只有一行数据，此时 type 为 system。 1234567mysql&gt; explain select * from (select * from test2 where id = 1000)a;+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+| 1 | PRIMARY | &lt;derived2&gt; | system | NULL | NULL | NULL | NULL | 1 | NULL || 2 | DERIVED | test2 | const | PRIMARY | PRIMARY | 8 | const | 1 | NULL |+----+-------------+------------+--------+---------------+---------+---------+-------+------+-------+ 4.2、const​ 确定只有一行匹配的时候，mysql 优化器会在查询前读取它并且只读一次，速度非常快。 4.3、eq_ref​ 对于每个来自于前表的行组合，从该表中读取一行，常用在一个索引是 unique key 或者 primary key 。 4.4、ref​ 对于来自前面的表的行组合，所有有匹配索引值的行都从这张表中读取，如果联接只使用键的最左边的前缀，或如果键不是 unique key 或 primary key（换句话说，如果联接不能基于关键字选择单个行的话），则使用 ref。 ​ ref 可以用于使用 &#x3D; 或 &lt;&#x3D;&gt; 操作符的带索引的列。 1234567mysql&gt; explain select * from test ,test2 where test.bnet_id=test2.aid;+----+-------------+-------+------+---------------+---------+---------+-------------------+-------+-----------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+---------------+---------+---------+-------------------+-------+-----------------------+| 1 | SIMPLE | test | ALL | NULL | NULL | NULL | NULL | 68505 | Using where || 1 | SIMPLE | test2 | ref | idx_aid | idx_aid | 5 | test.test.bnet_id | 34266 | Using index condition |+----+-------------+-------+------+---------------+---------+---------+-------------------+-------+-----------------------+ test表bnet_id不是索引，test2表aid为索引列。 4.5、ref_or_null​ 类似 ref, 但是添加了可以专门搜索 null 值的行。 123456mysql&gt; explain select * from test where bnet_id=1 or bnet_id is null;+----+-------------+-------+-------------+---------------+----------+---------+-------+------+-----------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------------+---------------+----------+---------+-------+------+-----------------------+| 1 | SIMPLE | test | ref_or_null | idx_bnet | idx_bnet | 9 | const | 2 | Using index condition |+----+-------------+-------+-------------+---------------+----------+---------+-------+------+-----------------------+ 前提为bnet_id列为索引，且bnet_id列有null值 4.6、index_merge​ 该访问类型使用了索引合并优化方法，key 列包含了使用的索引的清单，key_len 包含了使用的索引的最长的关键元素。 123456mysql&gt; explain select * from test where id = 1 or bnet_id = 1;+----+-------------+-------+-------------+------------------+------------------+---------+------+------+--------------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------------+------------------+------------------+---------+------+------+--------------------------------------------+| 1 | SIMPLE | test | index_merge | PRIMARY,idx_bnet | PRIMARY,idx_bnet | 8,9 | NULL | 2 | Using union(PRIMARY,idx_bnet); Using where |+----+-------------+-------+-------------+------------------+------------------+---------+------+------+--------------------------------------------+ ​ 前提条件为id列和bnet_id列都有单列索引。如果出现index_merge，并且这类SQL后期使用较频繁，可以考虑把单列索引换为组合索引，这样效率更高 4.7、range​ 只检索给定范围的行，使用一个索引来选择行。 key 列显示使用了那个索引。key_len 包含所使用索引的最长关键字元素。该类型中ref 列为 NULL。 当使用&#x3D;、&lt;&gt;、&gt;、&gt;&#x3D;、&lt;、&lt;&#x3D;、IS NULL、&lt;&#x3D;&gt;、BETWEEN或者IN操作符，用常量比较关键字列时，可以使用range。 123456mysql&gt; explain select * from test where bnet_id &gt; 1000 and bnet_id &lt; 10000;+----+-------------+-------+-------+---------------+----------+---------+------+------+-----------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+---------------+----------+---------+------+------+-----------------------+| 1 | SIMPLE | test | range | idx_bnet | idx_bnet | 9 | NULL | 1 | Using index condition |+----+-------------+-------+-------+---------------+----------+---------+------+------+-----------------------+ 前提条件为bnet_id列有索引。 4.8、index​ 在进行统计时非常常见，此联接类型实际上会扫描索引树 123456mysql&gt; explain select count(*) from test;+----+-------------+-------+-------+---------------+----------+---------+------+-------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+---------------+----------+---------+------+-------+-------------+| 1 | SIMPLE | test | index | NULL | idx_bnet | 9 | NULL | 68505 | Using index |+----+-------------+-------+-------+---------------+----------+---------+------+-------+-------------+ 4.9、all​ 对于每个来自于先前的表的行组合，进行完整的表扫描，通常可以增加更多的索引而不要使用ALL，使得行能基于前面的表中的常数值或列值被检索出 123456mysql&gt; explain select * from test where create_time = &#x27;0000-00-00 00:00:00&#x27;;+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+| 1 | SIMPLE | test | ALL | NULL | NULL | NULL | NULL | 68505 | Using where |+----+-------------+-------+------+---------------+------+---------+------+-------+-------------+ 5、possible_keys​ possible_keys 是指在这个 SQL 中，mysql 可以使用这个索引去辅助查找记录，当查询涉及到的字段，都会被列出，但不一定被查询使用.若为空则表示没有可以使用的索引，此时可以通过检查 where 语句看是否可以引用某些列或者新建索引来提高性能。 6、key(重要)​ key 列显示的是当前表实际使用的索引，如果没有选择索引，则此列为 null，要想强制 MySQL 使用或忽视 possible_keys 列中的索引，在查询中使用 FORCE INDEX、USE INDEX 或者 IGNORE INDEX。 7、key_len​ key_len 列显示 MySQL 决定使用的键长度。如果 KEY 键是 NULL，则长度为 NULL。在不损失精确性的情况下，长度越短越好key len 的长度还和字符集有关, latin1一个字符占用1个字节, gbk 一个字符占用2个字节, utf8 一个字符占用3个字节。key_len 的计算法方法如下： 列类型 长度 备注 id int 4+1 int为4bytes,允许为NULL,加1byte id bigint not null 8 bigint为8bytes user char(30) utf8 30*3+1 utf8每个字符为3bytes,允许为NULL,加1byte user varchar(30) not null utf8 30*3+2 utf8每个字符为3bytes,变长数据类型,加2bytes user varchar(30) utf8 30*3+2+1 utf8每个字符为3bytes,允许为NULL,加1byte,变长数据类型,加2bytes detail text(10) utf8 30*3+2+1 TEXT截取部分,被视为动态列类型。 ​ key_len只指示了where中用于条件过滤时被选中的索引列，是不包含order by或group by这一部分被选中的索引列。 8、ref​ ref列用来显示使用哪个列或常数与key一起从表中选择相应的行。它显示的列的名字（或const），此列多数时候为null。 9、rows​ rows列显示的是mysql解析器认为执行此SQL时必须扫描的行数。此数值为一个预估值，不是具体值，通常比实际值小。 10、filtered​ 此参数为mysql 5.7 新加参数，指的是返回结果的行数所占需要读到的行（rows的值）的比例，对于使用join时，前一个表的结果集大小直接影响了循环的行数。 11、extra(重要)​ extra表示不在其他列并且也很重要的额外信息。 11.1、using index​ 该值表示这个SQL语句使用了覆盖索引（覆盖索引是指可以直接在索引列中得到想要的结果，而不用去回表），此时效率最高。 123456mysql&gt; explain select id from test;+----+-------------+-------+-------+---------------+----------+---------+------+-------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+---------------+----------+---------+------+-------+-------------+| 1 | SIMPLE | test | index | NULL | idx_bnet | 9 | NULL | 68505 | Using index |+----+-------------+-------+-------+---------------+----------+---------+------+-------+-------------+ ​ 这个例子中id字段为主键，但是key那里显示走的并不是主键索引，这个是因为mysql的所有二级索引中都会包含所有的主键信息，而mysql没有单独的存储主键索引，所以扫描二级索引的开销比全表扫描更快 11.2、using where​ 表示存储引擎搜到记录后进行了后过滤(POST-FILTER)，如果查询未能使用索引，using where的作用只是提醒我们mysql要用where条件过滤结果集。 123456mysql&gt; explain select * from test where id &gt; 1;+----+-------------+-------+-------+---------------+---------+---------+------+-------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+---------------+---------+---------+------+-------+-------------+| 1 | SIMPLE | test | range | PRIMARY | PRIMARY | 8 | NULL | 34252 | Using where |+----+-------------+-------+-------+---------------+---------+---------+------+-------+-------------+ 11.3、using temporary​ 表示mysql需要使用临时表来存储结果集，常见于排序和分组查询。 123456mysql&gt; explain select * from test where id in (1,2) group by bnet_id;+----+-------------+-------+-------+-----------------------------------------+---------+---------+------+------+----------------------------------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+-------+-----------------------------------------+---------+---------+------+------+----------------------------------------------+| 1 | SIMPLE | test | range | PRIMARY,IDX(event_key-bnet_Id),idx_bnet | PRIMARY | 8 | NULL | 2 | Using where; Using temporary; Using filesort |+----+-------------+-------+-------+-----------------------------------------+---------+---------+------+------+----------------------------------------------+ 11.4、using filesort​ 是指mysql无法利用索引直接完成排序（排序的字段不是索引字段），此时会用到缓冲空间来进行排序。 123456mysql&gt; explain select * from test order by bnet_id;+----+-------------+-------+------+---------------+------+---------+------+-------+----------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+---------------+------+---------+------+-------+----------------+| 1 | SIMPLE | test | ALL | NULL | NULL | NULL | NULL | 68505 | Using filesort |+----+-------------+-------+------+---------------+------+---------+------+-------+----------------+ 11.5、using join buffer​ 强调在获取连接条件时没有用到索引，并且需要连接缓冲区来存储中间结果。（性能可以通过添加索引或者修改连接字段改进）。 12345678mysql&gt; explain select * from test left join test2 on test.create_time = test2.create_time;+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+| 1 | SIMPLE | test | NULL | ALL | NULL | NULL | NULL | NULL | 959692 | 100.00 | NULL || 1 | SIMPLE | test2 | NULL | ALL | NULL | NULL | NULL | NULL | 958353 | 100.00 | Using where; Using join buffer (Block Nested Loop) |+----+-------------+-------+------------+------+---------------+------+---------+------+--------+----------+----------------------------------------------------+2 rows in set, 1 warning (0.00 sec) ​ Block Nested Loop 是指 Block Nested-Loop Join算法：将外层循环的行&#x2F;结果集存入 join buffer, 内层循环的每一行与整个buffer中的记录做比较，从而减少内层循环的次数。 11.6、impossible where​ 表示where条件导致没有返回的行。 123456mysql&gt; explain select * from test where id is null;+----+-------------+-------+------+---------------+------+---------+------+------+------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+-------+------+---------------+------+---------+------+------+------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Impossible WHERE |+----+-------------+-------+------+---------------+------+---------+------+------+------------------+ 11.7、using index condition​ 是mysql 5.6 之后新加的特性，结合mysql的ICP（Index Condition Pushdown）特性使用。主要是优化了可以在索引（仅限二级索引）上进行 like 查找 如果extra中出现多个上面结果，则表示顺序使用上面的方法进行解析查询。","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]},{"title":"mysql8配置用户权限","slug":"mysql8配置用户权限","date":"2024-06-04T08:14:11.000Z","updated":"2025-01-29T06:14:53.729Z","comments":true,"path":"2024/06/04/mysql8配置用户权限/","permalink":"http://example.com/2024/06/04/mysql8%E9%85%8D%E7%BD%AE%E7%94%A8%E6%88%B7%E6%9D%83%E9%99%90/","excerpt":"1、登录mysql由于我的 mysql8 是由 docker 启动，先通过 docker 命令进入mysql 容器，再使用 mysql 命令登录 mysql。 123456789101112131415161718192021docker exec -it mysql8[容器名称] bashbash-4.4# mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 8Server version: 8.0.36 MySQL Community Server - GPLCopyright (c) 2000, 2024, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#x27;help;&#x27; or &#x27;\\h&#x27; for help. Type &#x27;\\c&#x27; to clear the current input statement.#切换数据库实例mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed","text":"1、登录mysql由于我的 mysql8 是由 docker 启动，先通过 docker 命令进入mysql 容器，再使用 mysql 命令登录 mysql。 123456789101112131415161718192021docker exec -it mysql8[容器名称] bashbash-4.4# mysql -u root -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \\g.Your MySQL connection id is 8Server version: 8.0.36 MySQL Community Server - GPLCopyright (c) 2000, 2024, Oracle and/or its affiliates.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type &#x27;help;&#x27; or &#x27;\\h&#x27; for help. Type &#x27;\\c&#x27; to clear the current input statement.#切换数据库实例mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changed 2、用户操作2.1、查看用户1select host, user, authentication_string , plugin from user; 2.2、创建本地用户123456789101112# 创建一个用户名为admin，密码为 admin123456 的本地用户。create user &#x27;admin&#x27;@&#x27;localhost&#x27; identified by &#x27;admin123456&#x27;;# 使admin用户获得所有权限grant all privileges on *.* to &#x27;admin&#x27;@&#x27;localhost&#x27;;# 刷新授权才会生效flush privileges;# wzd_mianxi数据库创建用户wzd,并赋予权限create user &#x27;wzd&#x27;@&#x27;%&#x27; identified by &#x27;123456&#x27;;# 注意，数据库名不能设计成wzd-mianxi，否则授权会报错grant all privileges on wzd_mianxi.* to &#x27;wzd&#x27;@&#x27;%&#x27;;flush privileges; 2.3、创建外网可访问的用户123456# 创建一个用户名为admin，密码为 admin123456 的本地用户create user &#x27;admin&#x27;@&#x27;%&#x27; identified by &#x27;admin123456&#x27;;# 使admin用户获得所有权限grant all privileges on *.* to &#x27;admin&#x27;@&#x27;%&#x27;;# 刷新授权才会生效flush privileges; 2.4、修改用户12345678# 查询用户信息select * from user Where User=&#x27;admin&#x27; and Host=&#x27;localhost&#x27;;# 方式一：将用户名 admin 更新为 admin_newmrename user &#x27;admin&#x27;@&#x27;localhost&#x27; to &#x27;admin_new&#x27;@&#x27;localhost&#x27;;# 方式二：将用户名 admin 更新为 admin_newmupdate user set User=&#x27;admin_new&#x27; where User=&#x27;admin&#x27; and Host=&#x27;localhost&#x27;;# 刷新授权才会生效flush privileges; 2.5、删除用户123456# 方式一：删除指定用户drop user &#x27;admin&#x27;@&#x27;localhost&#x27;;# 方式二：删除指定用户delete from user Where User=&#x27;admin&#x27; and Host=&#x27;localhost&#x27;;# 刷新授权才会生效flush privileges; 3、操作用户权限3.1、查看用户权限1show grants for &#x27;admin&#x27;@&#x27;localhost&#x27;; 3.2、修改用户权限12345678# 使admin用户获得所有权限。grant all privileges on *.* to &#x27;admin&#x27;@&#x27;localhost&#x27;;# 使admin用户获得所有数据库中所有表的(*.*)select、insert、update、delete权限grant select,insert,update,delete on *.* to &#x27;admin&#x27;@&#x27;localhost&#x27;;# 如果只想让该用户访问某一个数据库写成：testdb.* 即可grant all privileges on testdb.* to &#x27;admin&#x27;@&#x27;localhost&#x27;;# 刷新授权才会生效flush privileges; 3.3、删除用户权限123456# 删除amdin用户在本地访问mysql时的所有权限revoke all privileges on *.* from &#x27;admin&#x27;@&#x27;localhost&#x27;;# 删除amdin用户在本地访问mysql时的insert和update权限revoke insert,update on testdb.* from &#x27;admin&#x27;@&#x27;localhost&#x27;;# 刷新授权才会生效flush privileges; 4、修改密码","categories":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"}]}],"categories":[{"name":"Stream","slug":"Stream","permalink":"http://example.com/categories/Stream/"},{"name":"分组排序","slug":"Stream/分组排序","permalink":"http://example.com/categories/Stream/%E5%88%86%E7%BB%84%E6%8E%92%E5%BA%8F/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"http://example.com/categories/Spring/SpringBoot/"},{"name":"docker","slug":"docker","permalink":"http://example.com/categories/docker/"},{"name":"maven","slug":"maven","permalink":"http://example.com/categories/maven/"},{"name":"nginx","slug":"nginx","permalink":"http://example.com/categories/nginx/"},{"name":"redis","slug":"redis","permalink":"http://example.com/categories/redis/"},{"name":"nacos","slug":"docker/nacos","permalink":"http://example.com/categories/docker/nacos/"},{"name":"redis","slug":"docker/redis","permalink":"http://example.com/categories/docker/redis/"},{"name":"nginx","slug":"docker/nginx","permalink":"http://example.com/categories/docker/nginx/"},{"name":"mysql","slug":"docker/mysql","permalink":"http://example.com/categories/docker/mysql/"},{"name":"zookeeper","slug":"docker/zookeeper","permalink":"http://example.com/categories/docker/zookeeper/"},{"name":"centos8","slug":"centos8","permalink":"http://example.com/categories/centos8/"},{"name":"firewall","slug":"centos8/firewall","permalink":"http://example.com/categories/centos8/firewall/"},{"name":"nacos","slug":"nacos","permalink":"http://example.com/categories/nacos/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://example.com/categories/zookeeper/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/categories/mysql/"}],"tags":[{"name":"Stream","slug":"Stream","permalink":"http://example.com/tags/Stream/"},{"name":"分组排序","slug":"分组排序","permalink":"http://example.com/tags/%E5%88%86%E7%BB%84%E6%8E%92%E5%BA%8F/"},{"name":"Spring","slug":"Spring","permalink":"http://example.com/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"http://example.com/tags/SpringBoot/"},{"name":"docker","slug":"docker","permalink":"http://example.com/tags/docker/"},{"name":"maven","slug":"maven","permalink":"http://example.com/tags/maven/"},{"name":"nginx","slug":"nginx","permalink":"http://example.com/tags/nginx/"},{"name":"redis","slug":"redis","permalink":"http://example.com/tags/redis/"},{"name":"nacos","slug":"nacos","permalink":"http://example.com/tags/nacos/"},{"name":"mysql","slug":"mysql","permalink":"http://example.com/tags/mysql/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://example.com/tags/zookeeper/"},{"name":"centos8","slug":"centos8","permalink":"http://example.com/tags/centos8/"},{"name":"firewall","slug":"firewall","permalink":"http://example.com/tags/firewall/"},{"name":"原创","slug":"原创","permalink":"http://example.com/tags/%E5%8E%9F%E5%88%9B/"}]}